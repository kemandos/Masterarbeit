{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "matplotlib          3.5.0\n",
       "nltk                3.6.7\n",
       "numpy               1.20.3\n",
       "pandas              1.3.4\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                         8.4.0\n",
       "anyio                       NA\n",
       "attr                        21.2.0\n",
       "babel                       2.9.1\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "bottleneck                  1.3.2\n",
       "brotli                      NA\n",
       "certifi                     2022.05.18.1\n",
       "cffi                        1.15.0\n",
       "charset_normalizer          2.0.12\n",
       "colorama                    0.4.4\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.5.1\n",
       "decorator                   5.1.0\n",
       "defusedxml                  0.7.1\n",
       "entrypoints                 0.3\n",
       "idna                        2.10\n",
       "ipykernel                   6.4.1\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.18.0\n",
       "jinja2                      3.0.3\n",
       "joblib                      1.1.0\n",
       "json5                       NA\n",
       "jsonschema                  3.2.0\n",
       "jupyter_server              1.4.1\n",
       "jupyterlab_server           2.8.2\n",
       "kiwisolver                  1.3.1\n",
       "markupsafe                  2.1.1\n",
       "matplotlib_inline           NA\n",
       "mkl                         2.4.0\n",
       "mpl_toolkits                NA\n",
       "nbclassic                   NA\n",
       "nbformat                    5.1.3\n",
       "nbinom_ufunc                NA\n",
       "nt                          NA\n",
       "ntsecuritycon               NA\n",
       "numexpr                     2.7.3\n",
       "packaging                   21.3\n",
       "parso                       0.8.2\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "prometheus_client           NA\n",
       "prompt_toolkit              3.0.20\n",
       "pvectorc                    NA\n",
       "pyarrow                     5.0.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.6.0\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pyexpat                     NA\n",
       "pygments                    2.10.0\n",
       "pyparsing                   3.0.4\n",
       "pyrsistent                  NA\n",
       "pythoncom                   NA\n",
       "pytz                        2022.1\n",
       "pywintypes                  NA\n",
       "regex                       2.5.114\n",
       "requests                    2.27.1\n",
       "scipy                       1.7.1\n",
       "send2trash                  NA\n",
       "six                         1.15.0\n",
       "sklearn                     1.0.1\n",
       "sniffio                     1.2.0\n",
       "socks                       1.7.1\n",
       "sphinxcontrib               NA\n",
       "storemagic                  NA\n",
       "threadpoolctl               2.2.0\n",
       "tornado                     6.1\n",
       "traitlets                   5.1.1\n",
       "typing_extensions           NA\n",
       "urllib3                     1.26.9\n",
       "wcwidth                     0.2.5\n",
       "win32api                    NA\n",
       "win32com                    NA\n",
       "win32con                    NA\n",
       "win32security               NA\n",
       "win32trace                  NA\n",
       "winerror                    NA\n",
       "zmq                         22.3.0\n",
       "zope                        NA\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             7.29.0\n",
       "jupyter_client      7.0.6\n",
       "jupyter_core        4.9.1\n",
       "jupyterlab          3.2.1\n",
       "notebook            6.4.6\n",
       "-----\n",
       "Python 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.22000-SP0\n",
       "-----\n",
       "Session information updated at 2022-06-11 21:42\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>jobTitle_eng</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Branche</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>jobDescription_eng</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>est_minSalary</th>\n",
       "      <th>est_maxSalary</th>\n",
       "      <th>postDate</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abschlussarbeit controlling business intelligence</td>\n",
       "      <td>final thesis controlling business intelligence</td>\n",
       "      <td>lidl stiftung &amp; co kg</td>\n",
       "      <td>neckarsulm</td>\n",
       "      <td>groß- &amp; einzelhandel</td>\n",
       "      <td>lidl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linde material handling rhein ruhr entwickelt ...</td>\n",
       "      <td>linde material handling rhein ruhr develops hi...</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22-05-2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abteilungsleiter datenmanagement data warehous...</td>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>dfv deutsche familienversicherung ag</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>dfv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location is flexible job purpose the role is f...</td>\n",
       "      <td>location is flexible job purpose the role is f...</td>\n",
       "      <td>en</td>\n",
       "      <td>103890.0</td>\n",
       "      <td>140900.0</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accumulation data analyst in accumulation and ...</td>\n",
       "      <td>accumulation data analyst in accumulation and ...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data engineer join us let care for tomorrow at...</td>\n",
       "      <td>data engineer join us let care for tomorrow at...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accumulation data engineer in accumulation and...</td>\n",
       "      <td>accumulation data engineer in accumulation and...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>join us let care for tomorrow at allianz globa...</td>\n",
       "      <td>join us let care for tomorrow at allianz globa...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>teltow</td>\n",
       "      <td>finanzdienstleister</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>3.5</td>\n",
       "      <td>wir übernehmen verantwortung für das nachhalti...</td>\n",
       "      <td>we take responsibility for the sustainable man...</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            jobTitle  \\\n",
       "0  abschlussarbeit controlling business intelligence   \n",
       "1  abteilungsleiter datenmanagement data warehous...   \n",
       "2  accumulation data analyst in accumulation and ...   \n",
       "3  accumulation data engineer in accumulation and...   \n",
       "4                           actuarial data scientist   \n",
       "\n",
       "                                        jobTitle_eng  \\\n",
       "0     final thesis controlling business intelligence   \n",
       "1  department head data management data warehouse...   \n",
       "2  accumulation data analyst in accumulation and ...   \n",
       "3  accumulation data engineer in accumulation and...   \n",
       "4                           actuarial data scientist   \n",
       "\n",
       "                                Company    Location               Branche  \\\n",
       "0                 lidl stiftung & co kg  neckarsulm  groß- & einzelhandel   \n",
       "1  dfv deutsche familienversicherung ag   frankfurt        versicherungen   \n",
       "2  allianz global corporate & specialty     münchen        versicherungen   \n",
       "3  allianz global corporate & specialty     münchen        versicherungen   \n",
       "4                 verti versicherung ag      teltow   finanzdienstleister   \n",
       "\n",
       "            CompanyGroup  Rating  \\\n",
       "0                   lidl     NaN   \n",
       "1                    dfv     NaN   \n",
       "2                allianz     NaN   \n",
       "3                allianz     NaN   \n",
       "4  verti versicherung ag     3.5   \n",
       "\n",
       "                                      jobDescription  \\\n",
       "0  linde material handling rhein ruhr entwickelt ...   \n",
       "1  location is flexible job purpose the role is f...   \n",
       "2  data engineer join us let care for tomorrow at...   \n",
       "3  join us let care for tomorrow at allianz globa...   \n",
       "4  wir übernehmen verantwortung für das nachhalti...   \n",
       "\n",
       "                                  jobDescription_eng org_lang  est_minSalary  \\\n",
       "0  linde material handling rhein ruhr develops hi...       de            NaN   \n",
       "1  location is flexible job purpose the role is f...       en       103890.0   \n",
       "2  data engineer join us let care for tomorrow at...       en            NaN   \n",
       "3  join us let care for tomorrow at allianz globa...       en            NaN   \n",
       "4  we take responsibility for the sustainable man...       de            NaN   \n",
       "\n",
       "   est_maxSalary    postDate  Unnamed: 13  \n",
       "0            NaN  22-05-2022            0  \n",
       "1       140900.0  25-05-2022            1  \n",
       "2            NaN  11-04-2022            2  \n",
       "3            NaN  11-04-2022            3  \n",
       "4            NaN  25-05-2022            4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Master/04_Analysis/04_02_ensi_skills_extraction/04_01_custom_analysis/04_01_cleaned_and_trunslated_dataset.csv\", encoding = \"utf-8\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>postDate</th>\n",
       "      <th>text_id</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2420</td>\n",
       "      <td>2420</td>\n",
       "      <td>2419</td>\n",
       "      <td>2420</td>\n",
       "      <td>2420</td>\n",
       "      <td>2420.000000</td>\n",
       "      <td>2420</td>\n",
       "      <td>2420</td>\n",
       "      <td>2420</td>\n",
       "      <td>2420.000000</td>\n",
       "      <td>2420.000000</td>\n",
       "      <td>2420.000000</td>\n",
       "      <td>2420.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1670</td>\n",
       "      <td>1493</td>\n",
       "      <td>350</td>\n",
       "      <td>94</td>\n",
       "      <td>1376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2406</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>deutsche bahn ag</td>\n",
       "      <td>berlin</td>\n",
       "      <td>it-services &amp; it-consulting</td>\n",
       "      <td>deutsche bahn ag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>corporate description as a communication speci...</td>\n",
       "      <td>de</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>119</td>\n",
       "      <td>48</td>\n",
       "      <td>330</td>\n",
       "      <td>269</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1408</td>\n",
       "      <td>425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.817769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1209.500000</td>\n",
       "      <td>19057.414876</td>\n",
       "      <td>22942.407438</td>\n",
       "      <td>20999.911157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.641058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>698.738148</td>\n",
       "      <td>30491.833844</td>\n",
       "      <td>37807.489389</td>\n",
       "      <td>33699.184961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>604.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1209.500000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1814.250000</td>\n",
       "      <td>53856.000000</td>\n",
       "      <td>65144.750000</td>\n",
       "      <td>57881.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2419.000000</td>\n",
       "      <td>118005.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>139002.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              jobTitle           Company Location  \\\n",
       "count             2420              2420     2419   \n",
       "unique            1670              1493      350   \n",
       "top     data scientist  deutsche bahn ag   berlin   \n",
       "freq               119                48      330   \n",
       "mean               NaN               NaN      NaN   \n",
       "std                NaN               NaN      NaN   \n",
       "min                NaN               NaN      NaN   \n",
       "25%                NaN               NaN      NaN   \n",
       "50%                NaN               NaN      NaN   \n",
       "75%                NaN               NaN      NaN   \n",
       "max                NaN               NaN      NaN   \n",
       "\n",
       "                           Industry      CompanyGroup       Rating  \\\n",
       "count                          2420              2420  2420.000000   \n",
       "unique                           94              1376          NaN   \n",
       "top     it-services & it-consulting  deutsche bahn ag          NaN   \n",
       "freq                            269                48          NaN   \n",
       "mean                            NaN               NaN     0.817769   \n",
       "std                             NaN               NaN     1.641058   \n",
       "min                             NaN               NaN     0.000000   \n",
       "25%                             NaN               NaN     0.000000   \n",
       "50%                             NaN               NaN     0.000000   \n",
       "75%                             NaN               NaN     0.000000   \n",
       "max                             NaN               NaN     5.000000   \n",
       "\n",
       "                                           jobDescription org_lang  \\\n",
       "count                                                2420     2420   \n",
       "unique                                               2406        2   \n",
       "top     corporate description as a communication speci...       de   \n",
       "freq                                                    2     1408   \n",
       "mean                                                  NaN      NaN   \n",
       "std                                                   NaN      NaN   \n",
       "min                                                   NaN      NaN   \n",
       "25%                                                   NaN      NaN   \n",
       "50%                                                   NaN      NaN   \n",
       "75%                                                   NaN      NaN   \n",
       "max                                                   NaN      NaN   \n",
       "\n",
       "          postDate      text_id     salary_low    salary_high    salary_mean  \n",
       "count         2420  2420.000000    2420.000000    2420.000000    2420.000000  \n",
       "unique          67          NaN            NaN            NaN            NaN  \n",
       "top     11-04-2022          NaN            NaN            NaN            NaN  \n",
       "freq           425          NaN            NaN            NaN            NaN  \n",
       "mean           NaN  1209.500000   19057.414876   22942.407438   20999.911157  \n",
       "std            NaN   698.738148   30491.833844   37807.489389   33699.184961  \n",
       "min            NaN     0.000000      -1.000000      -1.000000      -1.000000  \n",
       "25%            NaN   604.750000      -1.000000      -1.000000      -1.000000  \n",
       "50%            NaN  1209.500000      -1.000000      -1.000000      -1.000000  \n",
       "75%            NaN  1814.250000   53856.000000   65144.750000   57881.500000  \n",
       "max            NaN  2419.000000  118005.000000  160000.000000  139002.500000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1. Drop jobDescription, jobTitle\n",
    "# 2. Rename jobDescription_eng, jobTitle_eng to jobDescription, jobTitle\n",
    "# 3. Rename Branche to Industry\n",
    "# 4. Rename Unnamed 14 to text_id\n",
    "# 5. Fill NaN rows with -1,0,N.A.\n",
    "# 6. Drop duplicates with jobDescription and CompanyGroup\n",
    "# 7. Fill NaN rows with -1,0,N.A.\n",
    "# 8. Create new column salary_low, salary_high and salary_mean\n",
    "# 9. Drop est_minSalary and est_maxSalary\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(dataframe):\n",
    "\n",
    "    dataframe = dataframe.drop(columns=['jobDescription','jobTitle'])\n",
    "    dataframe = dataframe.rename(columns={'jobDescription_eng': 'jobDescription','jobTitle_eng': 'jobTitle','Branche': 'Industry','Unnamed: 13': 'text_id'})\n",
    "    dataframe.fillna({'est_minSalary':-1,'est_maxSalary':-1, 'Rating':0, 'Industry': 'N.A.'},inplace=True)\n",
    "    dataframe = dataframe.drop_duplicates(subset=['jobDescription','CompanyGroup'])\n",
    "    dataframe.fillna({'est_minSalary':-1,'est_maxSalary':-1, 'Rating':0, 'Industry': 'N.A.'},inplace=True)\n",
    "    dataframe['salary_low'] = dataframe['est_minSalary'].astype(int)\n",
    "    dataframe['salary_high'] = dataframe['est_maxSalary'].astype(int)\n",
    "    dataframe['salary_mean'] = (dataframe[\"salary_high\"] + dataframe['salary_low'])/2\n",
    "    dataframe = dataframe.drop(columns=['est_minSalary', 'est_maxSalary'], axis=1)\n",
    "    return dataframe\n",
    "\n",
    "    \n",
    "df = preprocess_data(df)\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>postDate</th>\n",
       "      <th>text_id</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2406</td>\n",
       "      <td>2406</td>\n",
       "      <td>2405</td>\n",
       "      <td>2406</td>\n",
       "      <td>2406</td>\n",
       "      <td>2406.000000</td>\n",
       "      <td>2406</td>\n",
       "      <td>2406</td>\n",
       "      <td>2406</td>\n",
       "      <td>2406.000000</td>\n",
       "      <td>2406.000000</td>\n",
       "      <td>2406.000000</td>\n",
       "      <td>2406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1661</td>\n",
       "      <td>1488</td>\n",
       "      <td>348</td>\n",
       "      <td>93</td>\n",
       "      <td>1370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2406</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>deutsche bahn ag</td>\n",
       "      <td>berlin</td>\n",
       "      <td>it-services &amp; it-consulting</td>\n",
       "      <td>deutsche bahn ag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linde material handling rhein ruhr develops hi...</td>\n",
       "      <td>de</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>117</td>\n",
       "      <td>48</td>\n",
       "      <td>329</td>\n",
       "      <td>267</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1399</td>\n",
       "      <td>419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.811887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1206.591438</td>\n",
       "      <td>19023.150457</td>\n",
       "      <td>22890.132585</td>\n",
       "      <td>20956.641521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.636003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>699.027987</td>\n",
       "      <td>30468.146089</td>\n",
       "      <td>37767.432535</td>\n",
       "      <td>33664.325355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>601.250000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1204.500000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1811.750000</td>\n",
       "      <td>53638.000000</td>\n",
       "      <td>65119.000000</td>\n",
       "      <td>57875.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2419.000000</td>\n",
       "      <td>118005.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>139002.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              jobTitle           Company Location  \\\n",
       "count             2406              2406     2405   \n",
       "unique            1661              1488      348   \n",
       "top     data scientist  deutsche bahn ag   berlin   \n",
       "freq               117                48      329   \n",
       "mean               NaN               NaN      NaN   \n",
       "std                NaN               NaN      NaN   \n",
       "min                NaN               NaN      NaN   \n",
       "25%                NaN               NaN      NaN   \n",
       "50%                NaN               NaN      NaN   \n",
       "75%                NaN               NaN      NaN   \n",
       "max                NaN               NaN      NaN   \n",
       "\n",
       "                           Industry      CompanyGroup       Rating  \\\n",
       "count                          2406              2406  2406.000000   \n",
       "unique                           93              1370          NaN   \n",
       "top     it-services & it-consulting  deutsche bahn ag          NaN   \n",
       "freq                            267                48          NaN   \n",
       "mean                            NaN               NaN     0.811887   \n",
       "std                             NaN               NaN     1.636003   \n",
       "min                             NaN               NaN     0.000000   \n",
       "25%                             NaN               NaN     0.000000   \n",
       "50%                             NaN               NaN     0.000000   \n",
       "75%                             NaN               NaN     0.000000   \n",
       "max                             NaN               NaN     5.000000   \n",
       "\n",
       "                                           jobDescription org_lang  \\\n",
       "count                                                2406     2406   \n",
       "unique                                               2406        2   \n",
       "top     linde material handling rhein ruhr develops hi...       de   \n",
       "freq                                                    1     1399   \n",
       "mean                                                  NaN      NaN   \n",
       "std                                                   NaN      NaN   \n",
       "min                                                   NaN      NaN   \n",
       "25%                                                   NaN      NaN   \n",
       "50%                                                   NaN      NaN   \n",
       "75%                                                   NaN      NaN   \n",
       "max                                                   NaN      NaN   \n",
       "\n",
       "          postDate      text_id     salary_low    salary_high    salary_mean  \n",
       "count         2406  2406.000000    2406.000000    2406.000000    2406.000000  \n",
       "unique          67          NaN            NaN            NaN            NaN  \n",
       "top     11-04-2022          NaN            NaN            NaN            NaN  \n",
       "freq           419          NaN            NaN            NaN            NaN  \n",
       "mean           NaN  1206.591438   19023.150457   22890.132585   20956.641521  \n",
       "std            NaN   699.027987   30468.146089   37767.432535   33664.325355  \n",
       "min            NaN     0.000000      -1.000000      -1.000000      -1.000000  \n",
       "25%            NaN   601.250000      -1.000000      -1.000000      -1.000000  \n",
       "50%            NaN  1204.500000      -1.000000      -1.000000      -1.000000  \n",
       "75%            NaN  1811.750000   53638.000000   65119.000000   57875.750000  \n",
       "max            NaN  2419.000000  118005.000000  160000.000000  139002.500000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first line of code drops any duplicate rows in the 'jobDescription' column of the df dataframe. The second line of code displays summary statistics for all columns in the dataframe, including the 'jobDescription' column.\n",
    "\n",
    "df.drop_duplicates(subset=['jobDescription'],inplace=True)\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2406\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>postDate</th>\n",
       "      <th>text_id</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_mean</th>\n",
       "      <th>job_title_token</th>\n",
       "      <th>job_title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>final thesis controlling business intelligence</td>\n",
       "      <td>lidl stiftung &amp; co kg</td>\n",
       "      <td>neckarsulm</td>\n",
       "      <td>groß- &amp; einzelhandel</td>\n",
       "      <td>lidl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linde material handling rhein ruhr develops hi...</td>\n",
       "      <td>de</td>\n",
       "      <td>22-05-2022</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[final, thesis, controlling, business, intelli...</td>\n",
       "      <td>final thesis controlling business intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>dfv deutsche familienversicherung ag</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>dfv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location is flexible job purpose the role is f...</td>\n",
       "      <td>en</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>1</td>\n",
       "      <td>103890</td>\n",
       "      <td>140900</td>\n",
       "      <td>122395.0</td>\n",
       "      <td>[department, head, data, management, data, war...</td>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            jobTitle  \\\n",
       "0     final thesis controlling business intelligence   \n",
       "1  department head data management data warehouse...   \n",
       "\n",
       "                                Company    Location              Industry  \\\n",
       "0                 lidl stiftung & co kg  neckarsulm  groß- & einzelhandel   \n",
       "1  dfv deutsche familienversicherung ag   frankfurt        versicherungen   \n",
       "\n",
       "  CompanyGroup  Rating                                     jobDescription  \\\n",
       "0         lidl     0.0  linde material handling rhein ruhr develops hi...   \n",
       "1          dfv     0.0  location is flexible job purpose the role is f...   \n",
       "\n",
       "  org_lang    postDate  text_id  salary_low  salary_high  salary_mean  \\\n",
       "0       de  22-05-2022        0          -1           -1         -1.0   \n",
       "1       en  25-05-2022        1      103890       140900     122395.0   \n",
       "\n",
       "                                     job_title_token  \\\n",
       "0  [final, thesis, controlling, business, intelli...   \n",
       "1  [department, head, data, management, data, war...   \n",
       "\n",
       "                                     job_title_clean  \n",
       "0     final thesis controlling business intelligence  \n",
       "1  department head data management data warehouse...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# The first line of code defines a list of stop words, which are words that are commonly used in the English language but don't hold a lot of meaning, such as \"the\" or \"and\". \n",
    "# The second line of code defines a list of characters that should be removed from the job titles, such as punctuation marks and digits. The third line of code defines a function that takes in a dataframe as an argument. \n",
    "# This function tokenizes the job titles, which means it splits them up into individual words. It also removes any stop words or punctuation marks. Finally, it detokenizes the job titles, which means it puts them back together into a single string. \n",
    "# The fourth line of code applies this function to the dataframe. The fifth line of code prints the number of rows in the dataframe. The sixth line of code prints the first two rows of the dataframe.stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "to_remove = stop_words + list(string.punctuation) + list(string.digits)\n",
    "def tokenazing_job_titles(dataframe):\n",
    "    dataframe['job_title_token'] = dataframe['jobTitle'].apply(word_tokenize).apply(lambda x: [item for item in x if item not in to_remove])\n",
    "    dataframe['job_title_clean'] = dataframe['job_title_token'].apply(TreebankWordDetokenizer().detokenize)\n",
    "    dataframe['job_title_clean'] = dataframe['job_title_clean'].str.replace('/', ' ')\n",
    "    dataframe['job_title_clean'] = dataframe['job_title_clean'].str.replace('-', ' ')\n",
    "    dataframe['job_title_clean'] = dataframe['job_title_clean'].str.replace('.', ' ')\n",
    "    return dataframe\n",
    "df = tokenazing_job_titles(df)\n",
    "print(df.shape[0])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with seniority level:\n",
      " mid        1601\n",
      "senior      437\n",
      "junior      170\n",
      "manager     114\n",
      "head         20\n",
      "Name: level, dtype: int64\n",
      "Number of jobs with seniority level:\n",
      " 2342\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>postDate</th>\n",
       "      <th>text_id</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_mean</th>\n",
       "      <th>job_title_token</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>dfv deutsche familienversicherung ag</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>dfv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location is flexible job purpose the role is f...</td>\n",
       "      <td>en</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>1</td>\n",
       "      <td>103890</td>\n",
       "      <td>140900</td>\n",
       "      <td>122395.0</td>\n",
       "      <td>[department, head, data, management, data, war...</td>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accumulation data analyst in accumulation and ...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data engineer join us let care for tomorrow at...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[accumulation, data, analyst, accumulation, ca...</td>\n",
       "      <td>accumulation data analyst accumulation catastr...</td>\n",
       "      <td>mid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            jobTitle  \\\n",
       "1  department head data management data warehouse...   \n",
       "2  accumulation data analyst in accumulation and ...   \n",
       "\n",
       "                                Company   Location        Industry  \\\n",
       "1  dfv deutsche familienversicherung ag  frankfurt  versicherungen   \n",
       "2  allianz global corporate & specialty    münchen  versicherungen   \n",
       "\n",
       "  CompanyGroup  Rating                                     jobDescription  \\\n",
       "1          dfv     0.0  location is flexible job purpose the role is f...   \n",
       "2      allianz     0.0  data engineer join us let care for tomorrow at...   \n",
       "\n",
       "  org_lang    postDate  text_id  salary_low  salary_high  salary_mean  \\\n",
       "1       en  25-05-2022        1      103890       140900     122395.0   \n",
       "2       en  11-04-2022        2          -1           -1         -1.0   \n",
       "\n",
       "                                     job_title_token  \\\n",
       "1  [department, head, data, management, data, war...   \n",
       "2  [accumulation, data, analyst, accumulation, ca...   \n",
       "\n",
       "                                     job_title_clean level  \n",
       "1  department head data management data warehouse...  head  \n",
       "2  accumulation data analyst accumulation catastr...   mid  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code is used to determine the seniority level of a given job title. It does this by extracting certain keywords from the job title that indicate the seniority level, and thenreplace those keywords with labels indicating the seniority level. \n",
    "# For example, if the job title contains the word \"vice president\", it will be replaced with the label \"exec\".\n",
    "\n",
    "# The code first defines a function called \"seniority_level\" that takes in a dataframe as an input. It then creates a new column in the dataframe called \"level\", which contains the seniority level labels.\n",
    "\n",
    "# Next, the code uses the \"str.extract\" function to extract keywords from the \"job_title_clean\" column that indicate the seniority level. The extracted keywords are then replaced with labels indicating the seniority level.\n",
    "\n",
    "# Finally, the code fills in any missing values in the \"level\" column with the label \"mid\" and removes any rows that contain the word \"student\" or \"internship\" in the \"jobTitle\" column.\n",
    "\n",
    "\n",
    "\n",
    "def seniority_level(dataframe):\n",
    "    \n",
    "    dataframe['level'] = dataframe['job_title_clean'].str.extract('(vice president|vp|senior|junior|principal|president|associate|sr|sr.|jr|jr.|director|chief|manager|lead|head|entry|trainee|trainees|student|internship)')\n",
    "    dataframe['level'] = dataframe['level'].replace(\"(vice president|vp)\", 'exec', regex = True)\n",
    "    dataframe['level'] = dataframe['level'].replace(\"(chief|director)\", 'head', regex = True)\n",
    "    dataframe['level'] = dataframe['level'].replace(\"(lead|principal|manager)\", 'manager', regex = True)\n",
    "    dataframe['level'] = dataframe['level'].replace(\"(senior|sr|sr.)\", 'senior', regex = True)\n",
    "    dataframe['level'] = dataframe['level'].replace(\"(associate|staff)\", 'mid', regex = True)\n",
    "    dataframe['level'] = dataframe['level'].replace(\"(junior|jr|entry|trainee|trainees)\", 'junior', regex = True)\n",
    "    dataframe['level'] = dataframe['level'].replace(\"(student|internship)\", 'student', regex = True)\n",
    "    dataframe.level.fillna('mid', inplace = True)\n",
    "    dataframe = dataframe.query('level != \"student\"')\n",
    "    dataframe = dataframe[dataframe['jobTitle'].str.contains(\"thesis\")==False]\n",
    "\n",
    "    return dataframe\n",
    "df = seniority_level(df)\n",
    "print(F\"Number of jobs with seniority level:\\n {df.level.value_counts()}\")\n",
    "print(F\"Number of jobs with seniority level:\\n {df.shape[0]}\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below is creating a new column in the dataframe called 'role', and then using the .str.extract() function to pull out the roles from the 'job_title_clean' column. \n",
    "# The roles that are being extracted are:\n",
    "#                                       'data scientist', 'data engineer', 'data analysis', 'business analyst', 'bi', 'intelligence', 'data analyst', 'web', 'machine learning engineer', \n",
    "#                                       'data science', 'data engineering', 'analyst', 'analytics', 'research', 'scientist', 'science', 'engineer', 'data warehouse architect', 'data warehouse specialist', \n",
    "#                                       'data architect'.\n",
    "\n",
    "\n",
    "\n",
    "df['role'] = df['job_title_clean'].str.extract('(data scientist|data engineer|data analysis|business analyst|bi|intelligence|data analyst|web|machine learning engineer|\\\n",
    "                                                data science|data engineering|analyst|analytics|research|scientist|science|engineer|data warehouse architect|data warehouse specialist|data architect)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2311\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>postDate</th>\n",
       "      <th>text_id</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_mean</th>\n",
       "      <th>job_title_token</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>level</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>dfv deutsche familienversicherung ag</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>dfv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location is flexible job purpose the role is f...</td>\n",
       "      <td>en</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>1</td>\n",
       "      <td>103890</td>\n",
       "      <td>140900</td>\n",
       "      <td>122395.0</td>\n",
       "      <td>[department, head, data, management, data, war...</td>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>head</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accumulation data analyst in accumulation and ...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data engineer join us let care for tomorrow at...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[accumulation, data, analyst, accumulation, ca...</td>\n",
       "      <td>accumulation data analyst accumulation catastr...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accumulation data engineer in accumulation and...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>join us let care for tomorrow at allianz globa...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[accumulation, data, engineer, accumulation, c...</td>\n",
       "      <td>accumulation data engineer accumulation catast...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>teltow</td>\n",
       "      <td>finanzdienstleister</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>3.5</td>\n",
       "      <td>we take responsibility for the sustainable man...</td>\n",
       "      <td>de</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[actuarial, data, scientist]</td>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>hannover</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hirschau central full time about us conrad con...</td>\n",
       "      <td>de</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[actuarial, data, scientist, actuar]</td>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            jobTitle  \\\n",
       "1  department head data management data warehouse...   \n",
       "2  accumulation data analyst in accumulation and ...   \n",
       "3  accumulation data engineer in accumulation and...   \n",
       "4                           actuarial data scientist   \n",
       "5                    actuarial data scientist actuar   \n",
       "\n",
       "                                  Company   Location             Industry  \\\n",
       "1    dfv deutsche familienversicherung ag  frankfurt       versicherungen   \n",
       "2    allianz global corporate & specialty    münchen       versicherungen   \n",
       "3    allianz global corporate & specialty    münchen       versicherungen   \n",
       "4                   verti versicherung ag     teltow  finanzdienstleister   \n",
       "5  concordia versicherungsgesellschaft ag   hannover       versicherungen   \n",
       "\n",
       "                             CompanyGroup  Rating  \\\n",
       "1                                     dfv     0.0   \n",
       "2                                 allianz     0.0   \n",
       "3                                 allianz     0.0   \n",
       "4                   verti versicherung ag     3.5   \n",
       "5  concordia versicherungsgesellschaft ag     0.0   \n",
       "\n",
       "                                      jobDescription org_lang    postDate  \\\n",
       "1  location is flexible job purpose the role is f...       en  25-05-2022   \n",
       "2  data engineer join us let care for tomorrow at...       en  11-04-2022   \n",
       "3  join us let care for tomorrow at allianz globa...       en  11-04-2022   \n",
       "4  we take responsibility for the sustainable man...       de  25-05-2022   \n",
       "5  hirschau central full time about us conrad con...       de  11-04-2022   \n",
       "\n",
       "   text_id  salary_low  salary_high  salary_mean  \\\n",
       "1        1      103890       140900     122395.0   \n",
       "2        2          -1           -1         -1.0   \n",
       "3        3          -1           -1         -1.0   \n",
       "4        4          -1           -1         -1.0   \n",
       "5        5          -1           -1         -1.0   \n",
       "\n",
       "                                     job_title_token  \\\n",
       "1  [department, head, data, management, data, war...   \n",
       "2  [accumulation, data, analyst, accumulation, ca...   \n",
       "3  [accumulation, data, engineer, accumulation, c...   \n",
       "4                       [actuarial, data, scientist]   \n",
       "5               [actuarial, data, scientist, actuar]   \n",
       "\n",
       "                                     job_title_clean level            role  \n",
       "1  department head data management data warehouse...  head   data engineer  \n",
       "2  accumulation data analyst accumulation catastr...   mid    data analyst  \n",
       "3  accumulation data engineer accumulation catast...   mid   data engineer  \n",
       "4                           actuarial data scientist   mid  data scientist  \n",
       "5                    actuarial data scientist actuar   mid  data scientist  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code is extracting the role column from a dataframe, and replacing the various job titles with 3 simplified job titles - 'data engineer', 'data analyst', and 'data scientist'. \n",
    "# It then prints the number of rows in the dataframe, and returns the first 5 rows.\n",
    "\n",
    "\n",
    "\n",
    "df.dropna(subset=['role'], inplace=True)\n",
    "def extracting_role(dataframe):\n",
    "    dataframe['role'] = dataframe['role'].replace(\"(data engineer|engineer|machine learning engineer|data warehouse architect|data warehouse specialist|data architect)\", 'data engineer', regex = True)\n",
    "    dataframe['role'] = dataframe['role'].replace(\"(data analyst|analytics|analyst|web|data analysis|bi|intelligence)\", 'data analyst', regex = True)\n",
    "    dataframe['role'] = dataframe['role'].replace(\"(data scientist|data science|research|scientist|science)\", 'data scientist', regex = True)\n",
    "    return dataframe\n",
    "\n",
    "df = extracting_role(df)\n",
    "df_original_salary = df.copy()\n",
    "print(df.shape[0])\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>postDate</th>\n",
       "      <th>text_id</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_mean</th>\n",
       "      <th>job_title_token</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>level</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>dfv deutsche familienversicherung ag</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>dfv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location is flexible job purpose the role is f...</td>\n",
       "      <td>en</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>1</td>\n",
       "      <td>103890</td>\n",
       "      <td>140900</td>\n",
       "      <td>122395.0</td>\n",
       "      <td>[department, head, data, management, data, war...</td>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>head</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accumulation data analyst in accumulation and ...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data engineer join us let care for tomorrow at...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[accumulation, data, analyst, accumulation, ca...</td>\n",
       "      <td>accumulation data analyst accumulation catastr...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accumulation data engineer in accumulation and...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>join us let care for tomorrow at allianz globa...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[accumulation, data, engineer, accumulation, c...</td>\n",
       "      <td>accumulation data engineer accumulation catast...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>teltow</td>\n",
       "      <td>finanzdienstleister</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>3.5</td>\n",
       "      <td>we take responsibility for the sustainable man...</td>\n",
       "      <td>de</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[actuarial, data, scientist]</td>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>hannover</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hirschau central full time about us conrad con...</td>\n",
       "      <td>de</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[actuarial, data, scientist, actuar]</td>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            jobTitle  \\\n",
       "1  department head data management data warehouse...   \n",
       "2  accumulation data analyst in accumulation and ...   \n",
       "3  accumulation data engineer in accumulation and...   \n",
       "4                           actuarial data scientist   \n",
       "5                    actuarial data scientist actuar   \n",
       "\n",
       "                                  Company   Location             Industry  \\\n",
       "1    dfv deutsche familienversicherung ag  frankfurt       versicherungen   \n",
       "2    allianz global corporate & specialty    münchen       versicherungen   \n",
       "3    allianz global corporate & specialty    münchen       versicherungen   \n",
       "4                   verti versicherung ag     teltow  finanzdienstleister   \n",
       "5  concordia versicherungsgesellschaft ag   hannover       versicherungen   \n",
       "\n",
       "                             CompanyGroup  Rating  \\\n",
       "1                                     dfv     0.0   \n",
       "2                                 allianz     0.0   \n",
       "3                                 allianz     0.0   \n",
       "4                   verti versicherung ag     3.5   \n",
       "5  concordia versicherungsgesellschaft ag     0.0   \n",
       "\n",
       "                                      jobDescription org_lang    postDate  \\\n",
       "1  location is flexible job purpose the role is f...       en  25-05-2022   \n",
       "2  data engineer join us let care for tomorrow at...       en  11-04-2022   \n",
       "3  join us let care for tomorrow at allianz globa...       en  11-04-2022   \n",
       "4  we take responsibility for the sustainable man...       de  25-05-2022   \n",
       "5  hirschau central full time about us conrad con...       de  11-04-2022   \n",
       "\n",
       "   text_id  salary_low  salary_high  salary_mean  \\\n",
       "1        1      103890       140900     122395.0   \n",
       "2        2          -1           -1         -1.0   \n",
       "3        3          -1           -1         -1.0   \n",
       "4        4          -1           -1         -1.0   \n",
       "5        5          -1           -1         -1.0   \n",
       "\n",
       "                                     job_title_token  \\\n",
       "1  [department, head, data, management, data, war...   \n",
       "2  [accumulation, data, analyst, accumulation, ca...   \n",
       "3  [accumulation, data, engineer, accumulation, c...   \n",
       "4                       [actuarial, data, scientist]   \n",
       "5               [actuarial, data, scientist, actuar]   \n",
       "\n",
       "                                     job_title_clean level            role  \n",
       "1  department head data management data warehouse...  head   data engineer  \n",
       "2  accumulation data analyst accumulation catastr...   mid    data analyst  \n",
       "3  accumulation data engineer accumulation catast...   mid   data engineer  \n",
       "4                           actuarial data scientist   mid  data scientist  \n",
       "5                    actuarial data scientist actuar   mid  data scientist  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. This code creates a dataframe called df_base which only includes the columns: text_id, jobTitle, role, level, jobDescription, Location, Company, Industry\n",
    "# 2. Creates a dataframe called df_original_salary which only includes the columns: text_id, salary_low, salary_high, salary_mean\n",
    "# 3. Creates a copy of the df dataframe called df_furher_analysis\n",
    "\n",
    "\n",
    "\n",
    "df_base = df[['text_id','jobTitle','role','level','jobDescription','Location','Company','Industry']]\n",
    "df_base.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/00_tableau_base_data.xlsx',index=False)\n",
    "df_original_salary = df_original_salary[['text_id','salary_low','salary_high','salary_mean']]\n",
    "df_original_salary.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/02_tableau_original_salary.xlsx',index=False)\n",
    "\n",
    "\n",
    "df_furher_analysis = df.copy()\n",
    "df_furher_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>postDate</th>\n",
       "      <th>text_id</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_mean</th>\n",
       "      <th>job_title_token</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>level</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>dfv deutsche familienversicherung ag</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>dfv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location is flexible job purpose the role is f...</td>\n",
       "      <td>en</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>1</td>\n",
       "      <td>103890.0</td>\n",
       "      <td>140900.000000</td>\n",
       "      <td>122395.000000</td>\n",
       "      <td>[department, head, data, management, data, war...</td>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>head</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accumulation data analyst in accumulation and ...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data engineer join us let care for tomorrow at...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>2</td>\n",
       "      <td>64538.0</td>\n",
       "      <td>82615.833333</td>\n",
       "      <td>73576.916667</td>\n",
       "      <td>[accumulation, data, analyst, accumulation, ca...</td>\n",
       "      <td>accumulation data analyst accumulation catastr...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accumulation data engineer in accumulation and...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>join us let care for tomorrow at allianz globa...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>3</td>\n",
       "      <td>73200.0</td>\n",
       "      <td>73931.500000</td>\n",
       "      <td>73565.750000</td>\n",
       "      <td>[accumulation, data, engineer, accumulation, c...</td>\n",
       "      <td>accumulation data engineer accumulation catast...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>teltow</td>\n",
       "      <td>finanzdienstleister</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>3.5</td>\n",
       "      <td>we take responsibility for the sustainable man...</td>\n",
       "      <td>de</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[actuarial, data, scientist]</td>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>hannover</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hirschau central full time about us conrad con...</td>\n",
       "      <td>de</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>5</td>\n",
       "      <td>64172.0</td>\n",
       "      <td>84575.000000</td>\n",
       "      <td>74373.500000</td>\n",
       "      <td>[actuarial, data, scientist, actuar]</td>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            jobTitle  \\\n",
       "1  department head data management data warehouse...   \n",
       "2  accumulation data analyst in accumulation and ...   \n",
       "3  accumulation data engineer in accumulation and...   \n",
       "4                           actuarial data scientist   \n",
       "5                    actuarial data scientist actuar   \n",
       "\n",
       "                                  Company   Location             Industry  \\\n",
       "1    dfv deutsche familienversicherung ag  frankfurt       versicherungen   \n",
       "2    allianz global corporate & specialty    münchen       versicherungen   \n",
       "3    allianz global corporate & specialty    münchen       versicherungen   \n",
       "4                   verti versicherung ag     teltow  finanzdienstleister   \n",
       "5  concordia versicherungsgesellschaft ag   hannover       versicherungen   \n",
       "\n",
       "                             CompanyGroup  Rating  \\\n",
       "1                                     dfv     0.0   \n",
       "2                                 allianz     0.0   \n",
       "3                                 allianz     0.0   \n",
       "4                   verti versicherung ag     3.5   \n",
       "5  concordia versicherungsgesellschaft ag     0.0   \n",
       "\n",
       "                                      jobDescription org_lang    postDate  \\\n",
       "1  location is flexible job purpose the role is f...       en  25-05-2022   \n",
       "2  data engineer join us let care for tomorrow at...       en  11-04-2022   \n",
       "3  join us let care for tomorrow at allianz globa...       en  11-04-2022   \n",
       "4  we take responsibility for the sustainable man...       de  25-05-2022   \n",
       "5  hirschau central full time about us conrad con...       de  11-04-2022   \n",
       "\n",
       "   text_id  salary_low    salary_high    salary_mean  \\\n",
       "1        1    103890.0  140900.000000  122395.000000   \n",
       "2        2     64538.0   82615.833333   73576.916667   \n",
       "3        3     73200.0   73931.500000   73565.750000   \n",
       "4        4         NaN            NaN            NaN   \n",
       "5        5     64172.0   84575.000000   74373.500000   \n",
       "\n",
       "                                     job_title_token  \\\n",
       "1  [department, head, data, management, data, war...   \n",
       "2  [accumulation, data, analyst, accumulation, ca...   \n",
       "3  [accumulation, data, engineer, accumulation, c...   \n",
       "4                       [actuarial, data, scientist]   \n",
       "5               [actuarial, data, scientist, actuar]   \n",
       "\n",
       "                                     job_title_clean level            role  \n",
       "1  department head data management data warehouse...  head   data engineer  \n",
       "2  accumulation data analyst accumulation catastr...   mid    data analyst  \n",
       "3  accumulation data engineer accumulation catast...   mid   data engineer  \n",
       "4                           actuarial data scientist   mid  data scientist  \n",
       "5                    actuarial data scientist actuar   mid  data scientist  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing any Salary with -1 with the average salary of respective role, level and location\n",
    "\n",
    "\n",
    "# This code replaces the -1 values in salary_mean with the mean salary for the same role, level, and location.\n",
    "# The code first creates lists of unique jobs, ranks, and locations where salary_mean is -1.\n",
    "# It then loops through each job, rank, and location in the lists.\n",
    "# For each job, rank, and location, the code replaces the -1 values in salary_mean, salary_low, and salary_high with the mean salary for that job, rank, and location.\n",
    "\n",
    "\n",
    "\n",
    "def replacing_salary_role_level_location(dataframe):\n",
    "    jobs = dataframe[dataframe.salary_mean == -1].role.unique().tolist()\n",
    "    rank = dataframe[dataframe.salary_mean == -1].level.unique().tolist()\n",
    "    cities = dataframe[dataframe.salary_mean == -1].Location.unique().tolist()\n",
    "    for i in jobs:\n",
    "        for j in rank:\n",
    "            for c in cities:\n",
    "                dataframe['salary_mean'].mask(((dataframe['salary_mean'] == -1) & (dataframe['role'] == i) & (dataframe['level'] == j) & (dataframe['Location'] == c)), dataframe[(dataframe['role'] == i) & (dataframe['salary_mean'] != -1 ) & (dataframe['level'] == j)& (dataframe['Location'] == c)].salary_mean.mean(), inplace=True)\n",
    "                dataframe['salary_low'].mask(((dataframe['salary_low'] == -1) & (dataframe['role'] == i) & (dataframe['level'] == j) & (dataframe['Location'] == c)), dataframe[(dataframe['role'] == i) & (dataframe['salary_low'] != -1 ) & (dataframe['level'] == j)& (dataframe['Location'] == c)].salary_low.mean(), inplace=True)\n",
    "                dataframe['salary_high'].mask(((dataframe['salary_high'] == -1) & (dataframe['role'] == i) & (dataframe['level'] == j) & (dataframe['Location'] == c)), dataframe[(dataframe['role'] == i) & (dataframe['salary_high'] != -1 ) & (dataframe['level'] == j)& (dataframe['Location'] == c)].salary_high.mean(), inplace=True)\n",
    "    return dataframe\n",
    "df_furher_analysis = replacing_salary_role_level_location(df_furher_analysis)\n",
    "df_furher_analysis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>postDate</th>\n",
       "      <th>text_id</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_mean</th>\n",
       "      <th>job_title_token</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>level</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>dfv deutsche familienversicherung ag</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>dfv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location is flexible job purpose the role is f...</td>\n",
       "      <td>en</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>1</td>\n",
       "      <td>103890.000000</td>\n",
       "      <td>140900.000000</td>\n",
       "      <td>122395.000000</td>\n",
       "      <td>[department, head, data, management, data, war...</td>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>head</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accumulation data analyst in accumulation and ...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data engineer join us let care for tomorrow at...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>2</td>\n",
       "      <td>64538.000000</td>\n",
       "      <td>82615.833333</td>\n",
       "      <td>73576.916667</td>\n",
       "      <td>[accumulation, data, analyst, accumulation, ca...</td>\n",
       "      <td>accumulation data analyst accumulation catastr...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accumulation data engineer in accumulation and...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>join us let care for tomorrow at allianz globa...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>3</td>\n",
       "      <td>73200.000000</td>\n",
       "      <td>73931.500000</td>\n",
       "      <td>73565.750000</td>\n",
       "      <td>[accumulation, data, engineer, accumulation, c...</td>\n",
       "      <td>accumulation data engineer accumulation catast...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>teltow</td>\n",
       "      <td>finanzdienstleister</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>3.5</td>\n",
       "      <td>we take responsibility for the sustainable man...</td>\n",
       "      <td>de</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>4</td>\n",
       "      <td>70522.064556</td>\n",
       "      <td>68597.262764</td>\n",
       "      <td>69559.663660</td>\n",
       "      <td>[actuarial, data, scientist]</td>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>hannover</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hirschau central full time about us conrad con...</td>\n",
       "      <td>de</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>5</td>\n",
       "      <td>64172.000000</td>\n",
       "      <td>84575.000000</td>\n",
       "      <td>74373.500000</td>\n",
       "      <td>[actuarial, data, scientist, actuar]</td>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            jobTitle  \\\n",
       "1  department head data management data warehouse...   \n",
       "2  accumulation data analyst in accumulation and ...   \n",
       "3  accumulation data engineer in accumulation and...   \n",
       "4                           actuarial data scientist   \n",
       "5                    actuarial data scientist actuar   \n",
       "\n",
       "                                  Company   Location             Industry  \\\n",
       "1    dfv deutsche familienversicherung ag  frankfurt       versicherungen   \n",
       "2    allianz global corporate & specialty    münchen       versicherungen   \n",
       "3    allianz global corporate & specialty    münchen       versicherungen   \n",
       "4                   verti versicherung ag     teltow  finanzdienstleister   \n",
       "5  concordia versicherungsgesellschaft ag   hannover       versicherungen   \n",
       "\n",
       "                             CompanyGroup  Rating  \\\n",
       "1                                     dfv     0.0   \n",
       "2                                 allianz     0.0   \n",
       "3                                 allianz     0.0   \n",
       "4                   verti versicherung ag     3.5   \n",
       "5  concordia versicherungsgesellschaft ag     0.0   \n",
       "\n",
       "                                      jobDescription org_lang    postDate  \\\n",
       "1  location is flexible job purpose the role is f...       en  25-05-2022   \n",
       "2  data engineer join us let care for tomorrow at...       en  11-04-2022   \n",
       "3  join us let care for tomorrow at allianz globa...       en  11-04-2022   \n",
       "4  we take responsibility for the sustainable man...       de  25-05-2022   \n",
       "5  hirschau central full time about us conrad con...       de  11-04-2022   \n",
       "\n",
       "   text_id     salary_low    salary_high    salary_mean  \\\n",
       "1        1  103890.000000  140900.000000  122395.000000   \n",
       "2        2   64538.000000   82615.833333   73576.916667   \n",
       "3        3   73200.000000   73931.500000   73565.750000   \n",
       "4        4   70522.064556   68597.262764   69559.663660   \n",
       "5        5   64172.000000   84575.000000   74373.500000   \n",
       "\n",
       "                                     job_title_token  \\\n",
       "1  [department, head, data, management, data, war...   \n",
       "2  [accumulation, data, analyst, accumulation, ca...   \n",
       "3  [accumulation, data, engineer, accumulation, c...   \n",
       "4                       [actuarial, data, scientist]   \n",
       "5               [actuarial, data, scientist, actuar]   \n",
       "\n",
       "                                     job_title_clean level            role  \n",
       "1  department head data management data warehouse...  head   data engineer  \n",
       "2  accumulation data analyst accumulation catastr...   mid    data analyst  \n",
       "3  accumulation data engineer accumulation catast...   mid   data engineer  \n",
       "4                           actuarial data scientist   mid  data scientist  \n",
       "5                    actuarial data scientist actuar   mid  data scientist  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this function is used to replace the salary with the average salary of the role and level \n",
    "\n",
    "\n",
    "#This code is replacing the NaN values in the salary columns with the mean values of the salaries of the same roles and level.\n",
    "\n",
    "#Firstly, it replaces the NaN values with -1, so that it can easily distinguish which values have been changed to the mean.\n",
    "\n",
    "#It then creates two lists, jobs_2 and rank_2, which contain all of the roles and levels that have salary values of -1.\n",
    "\n",
    "#For each role in jobs_2 and each level in rank_2, it replaces the salary values of -1 with the mean salary value of that role and level.\n",
    "\n",
    "\n",
    "\n",
    "def replacing_salary_role_level(dataframe):\n",
    "    dataframe['salary_mean'] = dataframe['salary_mean'].replace(np.nan, -1)\n",
    "    dataframe['salary_low'] = dataframe['salary_low'].replace(np.nan, -1)\n",
    "    dataframe['salary_high'] = dataframe['salary_high'].replace(np.nan, -1)\n",
    "    jobs_2 = dataframe[dataframe.salary_mean == -1].role.unique().tolist()\n",
    "    rank_2 = dataframe[dataframe.salary_mean == -1].level.unique().tolist()\n",
    "    for i in jobs_2:\n",
    "        for j in rank_2: \n",
    "            dataframe['salary_mean'].mask(((dataframe['salary_mean'] == -1) & (dataframe['role'] == i) & (dataframe['level'] == j)), dataframe[(dataframe['role'] == i) & (dataframe['salary_mean'] != -1 ) & (dataframe['level'] == j)].salary_mean.mean(), inplace=True)\n",
    "            dataframe['salary_low'].mask(((dataframe['salary_low'] == -1) & (dataframe['role'] == i) & (dataframe['level'] == j)), dataframe[(dataframe['role'] == i) & (dataframe['salary_low'] != -1 ) & (dataframe['level'] == j)].salary_low.mean(), inplace=True)\n",
    "            dataframe['salary_high'].mask(((dataframe['salary_high'] == -1) & (dataframe['role'] == i) & (dataframe['level'] == j)), dataframe[(dataframe['role'] == i) & (dataframe['salary_high'] != -1 ) & (dataframe['level'] == j)].salary_high.mean(), inplace=True)\n",
    "    return dataframe\n",
    "df_furher_analysis = replacing_salary_role_level(df_furher_analysis)\n",
    "df_furher_analysis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves the custom salary dataframe to an excel file\n",
    "# The dataframe includes the text ID, low salary, high salary, and mean salary\n",
    "# The file is saved on the user's Desktop in the tableau data folder\n",
    "\n",
    "\n",
    "df_custom_salary = df_furher_analysis[['text_id','salary_low','salary_high','salary_mean']]\n",
    "df_custom_salary.to_excel('C:/Users/Aleksej Aikov/Desktop/Enablement/Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/03_tableau_custom_salary.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>postDate</th>\n",
       "      <th>text_id</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_mean</th>\n",
       "      <th>job_title_token</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>level</th>\n",
       "      <th>role</th>\n",
       "      <th>job_desc_token</th>\n",
       "      <th>job_desc_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>dfv deutsche familienversicherung ag</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>dfv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location is flexible job purpose the role is f...</td>\n",
       "      <td>en</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>1</td>\n",
       "      <td>103890.000000</td>\n",
       "      <td>140900.000000</td>\n",
       "      <td>122395.000000</td>\n",
       "      <td>[department, head, data, management, data, war...</td>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>head</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>[location, flexible, job, purpose, role, focus...</td>\n",
       "      <td>location flexible job purpose role focused add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accumulation data analyst in accumulation and ...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data engineer join us let care for tomorrow at...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>2</td>\n",
       "      <td>64538.000000</td>\n",
       "      <td>82615.833333</td>\n",
       "      <td>73576.916667</td>\n",
       "      <td>[accumulation, data, analyst, accumulation, ca...</td>\n",
       "      <td>accumulation data analyst accumulation catastr...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>[data, engineer, join, us, let, care, tomorrow...</td>\n",
       "      <td>data engineer join us let care tomorrow allian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accumulation data engineer in accumulation and...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>join us let care for tomorrow at allianz globa...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>3</td>\n",
       "      <td>73200.000000</td>\n",
       "      <td>73931.500000</td>\n",
       "      <td>73565.750000</td>\n",
       "      <td>[accumulation, data, engineer, accumulation, c...</td>\n",
       "      <td>accumulation data engineer accumulation catast...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>[join, us, let, care, tomorrow, allianz, globa...</td>\n",
       "      <td>join us let care tomorrow allianz global inves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>teltow</td>\n",
       "      <td>finanzdienstleister</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>3.5</td>\n",
       "      <td>we take responsibility for the sustainable man...</td>\n",
       "      <td>de</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>4</td>\n",
       "      <td>70522.064556</td>\n",
       "      <td>68597.262764</td>\n",
       "      <td>69559.663660</td>\n",
       "      <td>[actuarial, data, scientist]</td>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>[take, responsibility, sustainable, management...</td>\n",
       "      <td>take responsibility sustainable management ene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>hannover</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hirschau central full time about us conrad con...</td>\n",
       "      <td>de</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>5</td>\n",
       "      <td>64172.000000</td>\n",
       "      <td>84575.000000</td>\n",
       "      <td>74373.500000</td>\n",
       "      <td>[actuarial, data, scientist, actuar]</td>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>[hirschau, central, full, time, us, conrad, co...</td>\n",
       "      <td>hirschau central full time us conrad conquers ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            jobTitle  \\\n",
       "1  department head data management data warehouse...   \n",
       "2  accumulation data analyst in accumulation and ...   \n",
       "3  accumulation data engineer in accumulation and...   \n",
       "4                           actuarial data scientist   \n",
       "5                    actuarial data scientist actuar   \n",
       "\n",
       "                                  Company   Location             Industry  \\\n",
       "1    dfv deutsche familienversicherung ag  frankfurt       versicherungen   \n",
       "2    allianz global corporate & specialty    münchen       versicherungen   \n",
       "3    allianz global corporate & specialty    münchen       versicherungen   \n",
       "4                   verti versicherung ag     teltow  finanzdienstleister   \n",
       "5  concordia versicherungsgesellschaft ag   hannover       versicherungen   \n",
       "\n",
       "                             CompanyGroup  Rating  \\\n",
       "1                                     dfv     0.0   \n",
       "2                                 allianz     0.0   \n",
       "3                                 allianz     0.0   \n",
       "4                   verti versicherung ag     3.5   \n",
       "5  concordia versicherungsgesellschaft ag     0.0   \n",
       "\n",
       "                                      jobDescription org_lang    postDate  \\\n",
       "1  location is flexible job purpose the role is f...       en  25-05-2022   \n",
       "2  data engineer join us let care for tomorrow at...       en  11-04-2022   \n",
       "3  join us let care for tomorrow at allianz globa...       en  11-04-2022   \n",
       "4  we take responsibility for the sustainable man...       de  25-05-2022   \n",
       "5  hirschau central full time about us conrad con...       de  11-04-2022   \n",
       "\n",
       "   text_id     salary_low    salary_high    salary_mean  \\\n",
       "1        1  103890.000000  140900.000000  122395.000000   \n",
       "2        2   64538.000000   82615.833333   73576.916667   \n",
       "3        3   73200.000000   73931.500000   73565.750000   \n",
       "4        4   70522.064556   68597.262764   69559.663660   \n",
       "5        5   64172.000000   84575.000000   74373.500000   \n",
       "\n",
       "                                     job_title_token  \\\n",
       "1  [department, head, data, management, data, war...   \n",
       "2  [accumulation, data, analyst, accumulation, ca...   \n",
       "3  [accumulation, data, engineer, accumulation, c...   \n",
       "4                       [actuarial, data, scientist]   \n",
       "5               [actuarial, data, scientist, actuar]   \n",
       "\n",
       "                                     job_title_clean level            role  \\\n",
       "1  department head data management data warehouse...  head   data engineer   \n",
       "2  accumulation data analyst accumulation catastr...   mid    data analyst   \n",
       "3  accumulation data engineer accumulation catast...   mid   data engineer   \n",
       "4                           actuarial data scientist   mid  data scientist   \n",
       "5                    actuarial data scientist actuar   mid  data scientist   \n",
       "\n",
       "                                      job_desc_token  \\\n",
       "1  [location, flexible, job, purpose, role, focus...   \n",
       "2  [data, engineer, join, us, let, care, tomorrow...   \n",
       "3  [join, us, let, care, tomorrow, allianz, globa...   \n",
       "4  [take, responsibility, sustainable, management...   \n",
       "5  [hirschau, central, full, time, us, conrad, co...   \n",
       "\n",
       "                                      job_desc_clean  \n",
       "1  location flexible job purpose role focused add...  \n",
       "2  data engineer join us let care tomorrow allian...  \n",
       "3  join us let care tomorrow allianz global inves...  \n",
       "4  take responsibility sustainable management ene...  \n",
       "5  hirschau central full time us conrad conquers ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code tokenizes the job descriptions and removes stop words and punctuation\n",
    "\n",
    "# The first line imports the stopwords from the nltk library. The stopwords are common words that don't convey meaning and can be removed from the text.\n",
    "# The second line creates a list of stopwords and punctuation to be removed.\n",
    "# The third line tokenizes the job descriptions using the word_tokenize function from the nltk library. This function breaks the text into individual words.\n",
    "# The fourth line uses a list comprehension to remove the stopwords and punctuation from the tokenized text.\n",
    "# The fifth line detokenizes the text using the TreebankWordDetokenizer function from the nltk library. This function puts the text back together into sentences.\n",
    "# The sixth line returns the dataframe with the new columns.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tokenazing_job_description(dataframe):\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "    to_remove2 = stop_words + list(string.punctuation)\n",
    "    dataframe['job_desc_token'] = dataframe['jobDescription'].apply(word_tokenize).apply(lambda x: [item for item in x if item not in to_remove2])\n",
    "    dataframe['job_desc_clean'] = dataframe['job_desc_token'].apply(TreebankWordDetokenizer().detokenize)\n",
    "    return dataframe\n",
    "    \n",
    "df_furher_analysis = tokenazing_job_description(df_furher_analysis)\n",
    "df_furher_analysis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with degree mentioned: 1268\n",
      "Number of jobs without degree or not mentioned: 1043\n"
     ]
    }
   ],
   "source": [
    "# The function \"is_degree_required\" takes in one argument (a dataframe) and returns a dataframe.\n",
    "# This function is used to determine, based on the job description, whether a job requires a degree or not.\n",
    "\n",
    "# The first step is to replace some words in the job descriptions with other words. This is done using the \"replace\" method.\n",
    "# The reason for this is that some of the words that indicate that a degree is required are not always written in the same way.\n",
    "# For example, the word \"degree\" can also be written as \"completed studies\" or \"completed university degree\".\n",
    "\n",
    "# The second step is to use the \"str.contains\" method to check whether any of the replaced words are present in the job description.\n",
    "# This method returns a boolean value (True or False).\n",
    "# The result is then converted to an integer (0 or 1) using the \"astype\" method.\n",
    "\n",
    "# Finally, the function returns the dataframe with an additional column called \"degree_required\".\n",
    "\n",
    "\n",
    "\n",
    "def is_degree_required(dataframe):\n",
    "    dataframe['job_desc_clean'] = dataframe['job_desc_clean'].replace(\"(high degree of)\", 'high level of ', regex = True)\n",
    "    dataframe['job_desc_clean'] = dataframe['job_desc_clean'].replace(\"(nfortatik )\", 'informatics ', regex = True)\n",
    "    dataframe['job_desc_clean'] = dataframe['job_desc_clean'].replace(\"(you master)\", 'you are mastering ', regex = True) \n",
    "    dataframe['job_desc_clean'] = dataframe['job_desc_clean'].replace(\"(business informatist)\", 'business informatics', regex = True) \n",
    "    dataframe['job_desc_clean'] = dataframe['job_desc_clean'].replace(\"(informatist)\", 'informatics ', regex = True) \n",
    "    dataframe['job_desc_clean'] = dataframe['job_desc_clean'].replace(\"(wirtschaftswirtschaft|wirtschaft )\", 'business', regex = True)\n",
    "    dataframe['degree_required'] = dataframe['job_desc_clean'].str.contains(\"degree|completed studies|completed university degree|university degree|academic degree|completed study|study in the field|studies in the field\", case=False, regex=True).astype(int)\n",
    "    return dataframe\n",
    "df_furher_analysis = is_degree_required(df_furher_analysis)\n",
    "print(F'Number of jobs with degree mentioned: {df_furher_analysis[df_furher_analysis.degree_required == 1].shape[0]}')\n",
    "print(F'Number of jobs without degree or not mentioned: {df_furher_analysis[df_furher_analysis.degree_required == 0].shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with bachelor degree mentioned: 177\n",
      "Number of jobs with master degree mentioned: 401\n",
      "Number of jobs with phd degree mentioned: 82\n"
     ]
    }
   ],
   "source": [
    "# The code below is taking the dataframe \"df_furher_analysis\" and adding three new columns: \"bachelor\", \"master\", and \"phd\". \n",
    "# The new columns each have a binary value (0 or 1) depending on whether the corresponding word appears in the job description field of that row. \n",
    "# The function returns the updated dataframe.\n",
    "\n",
    "# The three print statements at the end are just calculating and printing the number of rows in which each word appears.\n",
    "\n",
    "\n",
    "def finding_degree_required(dataframe):\n",
    "\n",
    "    dataframe['job_desc_clean'] = dataframe['job_desc_clean'].replace(\"(sciencebusiness intelligence)\", 'business informatics', regex = True)\n",
    "    dataframe['job_desc_clean'] = dataframe['job_desc_clean'].replace(\"(wirtschaftswirtschaft|wirtschaft)\", 'business', regex = True)\n",
    "    dataframe['bachelor'] = dataframe['job_desc_clean'].str.contains(\"bachelor|bachelor's|bachelors|bachelor degree|bachelor's degree\", case=False, regex=True).astype(int)\n",
    "    dataframe['phd'] = dataframe['job_desc_clean'].str.contains(\"phd|ph.d|phd degree|ph.d degree\", case=False, regex=True).astype(int)\n",
    "    dataframe['master'] = dataframe['job_desc_clean'].str.contains(\"master|master's|masters|master degree|masters degree|master's degree|master of business|master of science|master of arts\", case=False, regex=True).astype(int)\n",
    "    return dataframe\n",
    "    \n",
    "df_furher_analysis = finding_degree_required(df_furher_analysis)\n",
    "\n",
    "print(F'Number of jobs with bachelor degree mentioned: {df_furher_analysis[df_furher_analysis.bachelor == 1].shape[0]}')\n",
    "print(F'Number of jobs with master degree mentioned: {df_furher_analysis[df_furher_analysis.master == 1].shape[0]}')\n",
    "print(F'Number of jobs with phd degree mentioned: {df_furher_analysis[df_furher_analysis.phd == 1].shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with degree mentioned: 1416\n",
      "Number of jobs with bachelor degree mentioned: 985\n",
      "Number of jobs with master degree mentioned: 349\n",
      "Number of jobs with phd degree mentioned: 82\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>postDate</th>\n",
       "      <th>text_id</th>\n",
       "      <th>...</th>\n",
       "      <th>job_title_token</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>level</th>\n",
       "      <th>role</th>\n",
       "      <th>job_desc_token</th>\n",
       "      <th>job_desc_clean</th>\n",
       "      <th>degree_required</th>\n",
       "      <th>bachelor</th>\n",
       "      <th>master</th>\n",
       "      <th>phd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>dfv deutsche familienversicherung ag</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>dfv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location is flexible job purpose the role is f...</td>\n",
       "      <td>en</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[department, head, data, management, data, war...</td>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>head</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>[location, flexible, job, purpose, role, focus...</td>\n",
       "      <td>location flexible job purpose role focused add...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accumulation data analyst in accumulation and ...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data engineer join us let care for tomorrow at...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[accumulation, data, analyst, accumulation, ca...</td>\n",
       "      <td>accumulation data analyst accumulation catastr...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>[data, engineer, join, us, let, care, tomorrow...</td>\n",
       "      <td>data engineer join us let care tomorrow allian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accumulation data engineer in accumulation and...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>join us let care for tomorrow at allianz globa...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[accumulation, data, engineer, accumulation, c...</td>\n",
       "      <td>accumulation data engineer accumulation catast...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>[join, us, let, care, tomorrow, allianz, globa...</td>\n",
       "      <td>join us let care tomorrow allianz global inves...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>teltow</td>\n",
       "      <td>finanzdienstleister</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>3.5</td>\n",
       "      <td>we take responsibility for the sustainable man...</td>\n",
       "      <td>de</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[actuarial, data, scientist]</td>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>[take, responsibility, sustainable, management...</td>\n",
       "      <td>take responsibility sustainable management ene...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>hannover</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hirschau central full time about us conrad con...</td>\n",
       "      <td>de</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>[actuarial, data, scientist, actuar]</td>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>[hirschau, central, full, time, us, conrad, co...</td>\n",
       "      <td>hirschau central full time us conrad conquers ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            jobTitle  \\\n",
       "1  department head data management data warehouse...   \n",
       "2  accumulation data analyst in accumulation and ...   \n",
       "3  accumulation data engineer in accumulation and...   \n",
       "4                           actuarial data scientist   \n",
       "5                    actuarial data scientist actuar   \n",
       "\n",
       "                                  Company   Location             Industry  \\\n",
       "1    dfv deutsche familienversicherung ag  frankfurt       versicherungen   \n",
       "2    allianz global corporate & specialty    münchen       versicherungen   \n",
       "3    allianz global corporate & specialty    münchen       versicherungen   \n",
       "4                   verti versicherung ag     teltow  finanzdienstleister   \n",
       "5  concordia versicherungsgesellschaft ag   hannover       versicherungen   \n",
       "\n",
       "                             CompanyGroup  Rating  \\\n",
       "1                                     dfv     0.0   \n",
       "2                                 allianz     0.0   \n",
       "3                                 allianz     0.0   \n",
       "4                   verti versicherung ag     3.5   \n",
       "5  concordia versicherungsgesellschaft ag     0.0   \n",
       "\n",
       "                                      jobDescription org_lang    postDate  \\\n",
       "1  location is flexible job purpose the role is f...       en  25-05-2022   \n",
       "2  data engineer join us let care for tomorrow at...       en  11-04-2022   \n",
       "3  join us let care for tomorrow at allianz globa...       en  11-04-2022   \n",
       "4  we take responsibility for the sustainable man...       de  25-05-2022   \n",
       "5  hirschau central full time about us conrad con...       de  11-04-2022   \n",
       "\n",
       "   text_id  ...                                    job_title_token  \\\n",
       "1        1  ...  [department, head, data, management, data, war...   \n",
       "2        2  ...  [accumulation, data, analyst, accumulation, ca...   \n",
       "3        3  ...  [accumulation, data, engineer, accumulation, c...   \n",
       "4        4  ...                       [actuarial, data, scientist]   \n",
       "5        5  ...               [actuarial, data, scientist, actuar]   \n",
       "\n",
       "                                     job_title_clean  level            role  \\\n",
       "1  department head data management data warehouse...   head   data engineer   \n",
       "2  accumulation data analyst accumulation catastr...    mid    data analyst   \n",
       "3  accumulation data engineer accumulation catast...    mid   data engineer   \n",
       "4                           actuarial data scientist    mid  data scientist   \n",
       "5                    actuarial data scientist actuar    mid  data scientist   \n",
       "\n",
       "                                      job_desc_token  \\\n",
       "1  [location, flexible, job, purpose, role, focus...   \n",
       "2  [data, engineer, join, us, let, care, tomorrow...   \n",
       "3  [join, us, let, care, tomorrow, allianz, globa...   \n",
       "4  [take, responsibility, sustainable, management...   \n",
       "5  [hirschau, central, full, time, us, conrad, co...   \n",
       "\n",
       "                                      job_desc_clean degree_required bachelor  \\\n",
       "1  location flexible job purpose role focused add...               1        0   \n",
       "2  data engineer join us let care tomorrow allian...               1        0   \n",
       "3  join us let care tomorrow allianz global inves...               1        0   \n",
       "4  take responsibility sustainable management ene...               1        1   \n",
       "5  hirschau central full time us conrad conquers ...               1        0   \n",
       "\n",
       "  master  phd  \n",
       "1      0    1  \n",
       "2      1    0  \n",
       "3      1    0  \n",
       "4      0    0  \n",
       "5      1    0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# This code is creating new columns in the dataframe to indicate which degree is required for each job.\n",
    "\n",
    "# The first column, 'degree_new', is set to 1 if any degree is required for the job, and 0 if no degree is required.\n",
    "\n",
    "# The second column, 'bachelor_new', is set to 1 if a bachelor's degree is required for the job, and 0 if not.\n",
    "\n",
    "# The third column, 'master_new', is set to 1 if a master's degree is required for the job, and 0 if not.\n",
    "\n",
    "# The fourth column, 'phd_new', is set to 1 if a PhD is required for the job, and 0 if not.\n",
    "\n",
    "# The original columns ('degree_required', 'bachelor', 'master', and 'phd') are then dropped, and the new columns are renamed to match the original column names.\n",
    "\n",
    "\n",
    "def cleaning_degree_and_degree_required(dataframe):\n",
    "\n",
    "    dataframe['degree_new']=dataframe.apply(lambda x : 1 if x['degree_required']!=0 or x['bachelor']!=0 or x['master']!=0 or x['phd']!=0 else 0, axis=1)\n",
    "    dataframe['bachelor_new']=dataframe.apply(lambda x : 1 if x['degree_new']==1 and x['master']==0 and x['phd']==0 else 0, axis=1)\n",
    "    dataframe['master_new']=dataframe.apply(lambda x : 1 if x['degree_new']==1 and x['bachelor_new']==0 and x['phd']==0 else 0, axis=1)\n",
    "    dataframe['phd_new']=dataframe.apply(lambda x : 1 if x['degree_new']==1 and x['bachelor_new']==0 and x['master_new']==0 else 0, axis=1)\n",
    "    dataframe = dataframe.drop(columns=['degree_required', 'bachelor', 'master', 'phd'])\n",
    "    dataframe.rename(columns={'degree_new': 'degree_required', 'bachelor_new': 'bachelor', 'master_new': 'master', 'phd_new': 'phd'}, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "df_furher_analysis = cleaning_degree_and_degree_required(df_furher_analysis)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(F'Number of jobs with degree mentioned: {df_furher_analysis[df_furher_analysis.degree_required == 1].shape[0]}')\n",
    "print(F'Number of jobs with bachelor degree mentioned: {df_furher_analysis[df_furher_analysis.bachelor == 1].shape[0]}')\n",
    "print(F'Number of jobs with master degree mentioned: {df_furher_analysis[df_furher_analysis.master == 1].shape[0]}')\n",
    "print(F'Number of jobs with phd degree mentioned: {df_furher_analysis[df_furher_analysis.phd == 1].shape[0]}')\n",
    "\n",
    "df_furher_analysis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is creating new columns in the dataframe df_further_analysis. \n",
    "# The new columns are related to different study fields, such as mathematics, statistics, physics, chemistry, biology, economics, business, computer science, economic engineering, business informatics, information management, information technology, computer engineering and computer science engineering. \n",
    "# For each of these columns, the code is checking if the job_desc_clean (which is a column in the dataframe) contains certain keywords related to the study field. \n",
    "# If the job_desc_clean contains the keyword, then the code will add a 1 to the column. If the job_desc_clean does not contain the keyword, then the code will add a 0 to the column.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def major_study_fields(dataframe):\n",
    "    \n",
    "    dataframe['mathematics'] = dataframe['job_desc_clean'].str.contains('math|mathematics', case=False, regex=True).astype(int)\n",
    "    dataframe['statistics'] = dataframe['job_desc_clean'].str.contains('statistics', case=False, regex=True).astype(int)\n",
    "    dataframe['physics'] = dataframe['job_desc_clean'].str.contains('physics', case=False, regex=True).astype(int)\n",
    "    dataframe['chemistry'] = dataframe['job_desc_clean'].str.contains('chemistry', case=False, regex=True).astype(int)\n",
    "    dataframe['biology'] = dataframe['job_desc_clean'].str.contains('biology', case=False, regex=True).astype(int)\n",
    "    dataframe['economics'] = dataframe['job_desc_clean'].str.contains('economics|economic science', case=False, regex=True).astype(int)\n",
    "    dataframe['business'] = dataframe['job_desc_clean'].str.contains('business administration|business economics|business sciences|bwl', case=False, regex=True).astype(int)\n",
    "    dataframe['computer_science'] = dataframe['job_desc_clean'].str.contains('computer science|informatics|software engineering|informatics', case=False, regex=True).astype(int)\n",
    "    dataframe['economic_engineering'] = dataframe['job_desc_clean'].str.contains('economic engineering|economic engineering system', case=False, regex=True).astype(int)\n",
    "    dataframe['business_informatics'] = dataframe['job_desc_clean'].str.contains('business informatics', case=False, regex=True).astype(int)\n",
    "    dataframe['information_management'] = dataframe['job_desc_clean'].str.contains('information management', case=False, regex=True).astype(int)\n",
    "    dataframe['information_technology'] = dataframe['job_desc_clean'].str.contains('information technology', case=False, regex=True).astype(int)\n",
    "    dataframe['computer_engineering'] = dataframe['job_desc_clean'].str.contains('computer engineering', case=False, regex=True).astype(int)\n",
    "    dataframe['computer_science engineering'] = dataframe['job_desc_clean'].str.contains('computer science engineering', case=False, regex=True).astype(int)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "df_furher_analysis = major_study_fields(df_furher_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with mathematics mentioned: 717\n",
      "Number of jobs with statistics mentioned: 479\n",
      "Number of jobs with physics mentioned: 226\n",
      "Number of jobs with chemistry mentioned: 19\n",
      "Number of jobs with biology mentioned: 10\n",
      "Number of jobs with economics mentioned: 251\n",
      "Number of jobs with business mentioned: 188\n",
      "Number of jobs with computer science mentioned: 1257\n",
      "Number of jobs with economic engineering mentioned: 16\n",
      "Number of jobs with business informatics mentioned: 364\n",
      "Number of jobs with information management mentioned: 17\n",
      "Number of jobs with information technology mentioned: 85\n",
      "Number of jobs with computer engineering mentioned: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>CompanyGroup</th>\n",
       "      <th>Rating</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>org_lang</th>\n",
       "      <th>postDate</th>\n",
       "      <th>text_id</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_mean</th>\n",
       "      <th>job_title_token</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>level</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>dfv deutsche familienversicherung ag</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>dfv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>location is flexible job purpose the role is f...</td>\n",
       "      <td>en</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>1</td>\n",
       "      <td>103890</td>\n",
       "      <td>140900</td>\n",
       "      <td>122395.0</td>\n",
       "      <td>[department, head, data, management, data, war...</td>\n",
       "      <td>department head data management data warehouse...</td>\n",
       "      <td>head</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accumulation data analyst in accumulation and ...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data engineer join us let care for tomorrow at...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[accumulation, data, analyst, accumulation, ca...</td>\n",
       "      <td>accumulation data analyst accumulation catastr...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accumulation data engineer in accumulation and...</td>\n",
       "      <td>allianz global corporate &amp; specialty</td>\n",
       "      <td>münchen</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>allianz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>join us let care for tomorrow at allianz globa...</td>\n",
       "      <td>en</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[accumulation, data, engineer, accumulation, c...</td>\n",
       "      <td>accumulation data engineer accumulation catast...</td>\n",
       "      <td>mid</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>teltow</td>\n",
       "      <td>finanzdienstleister</td>\n",
       "      <td>verti versicherung ag</td>\n",
       "      <td>3.5</td>\n",
       "      <td>we take responsibility for the sustainable man...</td>\n",
       "      <td>de</td>\n",
       "      <td>25-05-2022</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[actuarial, data, scientist]</td>\n",
       "      <td>actuarial data scientist</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>hannover</td>\n",
       "      <td>versicherungen</td>\n",
       "      <td>concordia versicherungsgesellschaft ag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hirschau central full time about us conrad con...</td>\n",
       "      <td>de</td>\n",
       "      <td>11-04-2022</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[actuarial, data, scientist, actuar]</td>\n",
       "      <td>actuarial data scientist actuar</td>\n",
       "      <td>mid</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            jobTitle  \\\n",
       "1  department head data management data warehouse...   \n",
       "2  accumulation data analyst in accumulation and ...   \n",
       "3  accumulation data engineer in accumulation and...   \n",
       "4                           actuarial data scientist   \n",
       "5                    actuarial data scientist actuar   \n",
       "\n",
       "                                  Company   Location             Industry  \\\n",
       "1    dfv deutsche familienversicherung ag  frankfurt       versicherungen   \n",
       "2    allianz global corporate & specialty    münchen       versicherungen   \n",
       "3    allianz global corporate & specialty    münchen       versicherungen   \n",
       "4                   verti versicherung ag     teltow  finanzdienstleister   \n",
       "5  concordia versicherungsgesellschaft ag   hannover       versicherungen   \n",
       "\n",
       "                             CompanyGroup  Rating  \\\n",
       "1                                     dfv     0.0   \n",
       "2                                 allianz     0.0   \n",
       "3                                 allianz     0.0   \n",
       "4                   verti versicherung ag     3.5   \n",
       "5  concordia versicherungsgesellschaft ag     0.0   \n",
       "\n",
       "                                      jobDescription org_lang    postDate  \\\n",
       "1  location is flexible job purpose the role is f...       en  25-05-2022   \n",
       "2  data engineer join us let care for tomorrow at...       en  11-04-2022   \n",
       "3  join us let care for tomorrow at allianz globa...       en  11-04-2022   \n",
       "4  we take responsibility for the sustainable man...       de  25-05-2022   \n",
       "5  hirschau central full time about us conrad con...       de  11-04-2022   \n",
       "\n",
       "   text_id  salary_low  salary_high  salary_mean  \\\n",
       "1        1      103890       140900     122395.0   \n",
       "2        2          -1           -1         -1.0   \n",
       "3        3          -1           -1         -1.0   \n",
       "4        4          -1           -1         -1.0   \n",
       "5        5          -1           -1         -1.0   \n",
       "\n",
       "                                     job_title_token  \\\n",
       "1  [department, head, data, management, data, war...   \n",
       "2  [accumulation, data, analyst, accumulation, ca...   \n",
       "3  [accumulation, data, engineer, accumulation, c...   \n",
       "4                       [actuarial, data, scientist]   \n",
       "5               [actuarial, data, scientist, actuar]   \n",
       "\n",
       "                                     job_title_clean level            role  \n",
       "1  department head data management data warehouse...  head   data engineer  \n",
       "2  accumulation data analyst accumulation catastr...   mid    data analyst  \n",
       "3  accumulation data engineer accumulation catast...   mid   data engineer  \n",
       "4                           actuarial data scientist   mid  data scientist  \n",
       "5                    actuarial data scientist actuar   mid  data scientist  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F'Number of jobs with mathematics mentioned: {df_furher_analysis[df_furher_analysis.mathematics == 1].shape[0]}')\n",
    "print(F'Number of jobs with statistics mentioned: {df_furher_analysis[df_furher_analysis.statistics == 1].shape[0]}')\n",
    "print(F'Number of jobs with physics mentioned: {df_furher_analysis[df_furher_analysis.physics == 1].shape[0]}')\n",
    "print(F'Number of jobs with chemistry mentioned: {df_furher_analysis[df_furher_analysis.chemistry == 1].shape[0]}')\n",
    "print(F'Number of jobs with biology mentioned: {df_furher_analysis[df_furher_analysis.biology == 1].shape[0]}')\n",
    "print(F'Number of jobs with economics mentioned: {df_furher_analysis[df_furher_analysis.economics == 1].shape[0]}')\n",
    "print(F'Number of jobs with business mentioned: {df_furher_analysis[df_furher_analysis.business == 1].shape[0]}')\n",
    "print(F'Number of jobs with computer science mentioned: {df_furher_analysis[df_furher_analysis.computer_science == 1].shape[0]}')\n",
    "print(F'Number of jobs with economic engineering mentioned: {df_furher_analysis[df_furher_analysis.economic_engineering == 1].shape[0]}')\n",
    "print(F'Number of jobs with business informatics mentioned: {df_furher_analysis[df_furher_analysis.business_informatics == 1].shape[0]}')\n",
    "print(F'Number of jobs with information management mentioned: {df_furher_analysis[df_furher_analysis.information_management == 1].shape[0]}')\n",
    "print(F'Number of jobs with information technology mentioned: {df_furher_analysis[df_furher_analysis.information_technology == 1].shape[0]}')\n",
    "print(F'Number of jobs with computer engineering mentioned: {df_furher_analysis[df_furher_analysis.computer_engineering == 1].shape[0]}')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is extracting data from a dataframe called df_furher_analysis. The data that is being extracted is based on the columns listed in the code. The data is then being exported to an excel file.\n",
    "\n",
    "\n",
    "df_degree_required = df_furher_analysis[['text_id', 'degree_required', 'bachelor', 'master', 'phd','mathematics', 'statistics', 'physics', 'chemistry', 'biology', 'economics', 'business', 'computer_science', \n",
    "                        'economic_engineering', 'business_informatics', 'information_management', 'information_technology', 'computer_engineering', 'computer_science engineering']]\n",
    "df_degree_required.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/04_tableau_analysis_degree_required.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is creating a new dataframe called df_visualization that only contains the text_id and job_desc_clean columns from the df_furher_analysis dataframe. \n",
    "\n",
    "# The code is then creating a list of visualization skills called visualization. \n",
    "\n",
    "# The code then defines a function called find_visualization_skills that takes two parameters, dataframe and *skills. The * in front of skills allows the function to take an arbitrary number of parameters. \n",
    "\n",
    "# The function finds all of the visualization skills in the job_desc_clean column and creates a new column for each of the skills in the list called visualization. The function then returns the dataframe. \n",
    "\n",
    "# The code then applies the find_visualization_skills function to the df_visualization dataframe using the list of visualization skills as the input. \n",
    "\n",
    "# The code then creates a new dataframe called df_visualization_skills that only contains the text_id, visualization, and the skills from the list. \n",
    "\n",
    "# The code then exports the df_visualization_skills dataframe to an Excel file.\n",
    "\n",
    "\n",
    "df_visualization = df_furher_analysis[['text_id','job_desc_clean']].copy()\n",
    "\n",
    "visualization = ['chartio','looker', 'zoho analytics','fusioncharts','cluvio','datawrapper','plotly','matplotlib','seaborn','dash','bokeh','highcharts',\n",
    "                'spotfire', 'rshiny', 'domo', 'webfocus','superset','google charts','sisense','chartblocks']\n",
    "def find_visualization_skills(dataframe, *skills):\n",
    "\n",
    "    dataframe['visualization'] = dataframe['job_desc_clean'].str.contains('visualisation|data visualisation|visualization|dashboarding|dashboard', case=False, regex=True).astype(int)\n",
    "    for skill in skills:\n",
    "        dataframe[skill] = dataframe['job_desc_clean'].str.contains(f'{skill}', case=False, regex=True).astype(int)\n",
    "        dataframe['power_bi'] = dataframe['job_desc_clean'].str.contains('powerbi|power bi', case=False, regex=True).astype(int)\n",
    "        dataframe['tableau'] = dataframe['job_desc_clean'].str.contains('tableau|tableau online', case=False, regex=True).astype(int)\n",
    "        dataframe['google_data_studio'] = dataframe['job_desc_clean'].str.contains('google data studio|data studio', case=False, regex=True).astype(int)\n",
    "        dataframe['qlik'] = dataframe['job_desc_clean'].str.contains('qlik|qlikview|qliksense|qlik sense', case=False, regex=True).astype(int)\n",
    "        dataframe.rename(columns={'google charts':'google_charts', 'zoho analytics':'zoho_analytics'}, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "df_visualization = find_visualization_skills(df_visualization, *visualization)   \n",
    "\n",
    "df_visualization_skills = df_visualization[['text_id', 'visualization','chartio','looker', 'zoho_analytics','fusioncharts','cluvio','datawrapper','plotly',\n",
    "                                            'matplotlib','seaborn','dash','bokeh','highcharts','spotfire','rshiny','domo','webfocus','superset','google_data_studio','sisense',\n",
    "                                            'chartblocks','power_bi','tableau','google_charts','qlik','chartblocks']].copy()\n",
    "df_visualization_skills.head(5)\n",
    "\n",
    "df_visualization_skills.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/05_tableau_analysis_visualization_skills.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with visualization mentioned: 627\n",
      "Number of jobs with chartio mentioned: 0\n",
      "Number of jobs with looker mentioned: 36\n",
      "Number of jobs with zoho analytics mentioned: 0\n",
      "Number of jobs with fusioncharts mentioned: 0\n",
      "Number of jobs with cluvio mentioned: 0\n",
      "Number of jobs with datawrapper mentioned: 2\n",
      "Number of jobs with plotly mentioned: 15\n",
      "Number of jobs with matplotlib mentioned: 13\n",
      "Number of jobs with seaborn mentioned: 5\n",
      "Number of jobs with dash mentioned: 358\n",
      "Number of jobs with bokeh mentioned: 0\n",
      "Number of jobs with highcharts mentioned: 0\n",
      "Number of jobs with spotfire mentioned: 5\n",
      "Number of jobs with rshiny mentioned: 1\n",
      "Number of jobs with domo mentioned: 0\n",
      "Number of jobs with webfocus mentioned: 3\n",
      "Number of jobs with superset mentioned: 6\n",
      "Number of jobs with google data studio mentioned: 37\n",
      "Number of jobs with sisense mentioned: 1\n",
      "Number of jobs with chartblocks mentioned: 0\n",
      "Number of jobs with power bi mentioned: 386\n",
      "Number of jobs with tableau mentioned: 287\n",
      "Number of jobs with qlik mentioned: 110\n",
      "Number of jobs with google charts mentioned: 0\n",
      "Number of jobs with zoho analytics mentioned: 0\n"
     ]
    }
   ],
   "source": [
    "print(F'Number of jobs with visualization mentioned: {df_visualization[df_visualization.visualization == 1].shape[0]}')\n",
    "print(F'Number of jobs with chartio mentioned: {df_visualization[df_visualization.chartio == 1].shape[0]}')\n",
    "print(F'Number of jobs with looker mentioned: {df_visualization[df_visualization.looker == 1].shape[0]}')\n",
    "print(F'Number of jobs with zoho analytics mentioned: {df_visualization[df_visualization.zoho_analytics == 1].shape[0]}')\n",
    "print(F'Number of jobs with fusioncharts mentioned: {df_visualization[df_visualization.fusioncharts == 1].shape[0]}')\n",
    "print(F'Number of jobs with cluvio mentioned: {df_visualization[df_visualization.cluvio == 1].shape[0]}')\n",
    "print(F'Number of jobs with datawrapper mentioned: {df_visualization[df_visualization.datawrapper == 1].shape[0]}')\n",
    "print(F'Number of jobs with plotly mentioned: {df_visualization[df_visualization.plotly == 1].shape[0]}')\n",
    "print(F'Number of jobs with matplotlib mentioned: {df_visualization[df_visualization.matplotlib == 1].shape[0]}')\n",
    "print(F'Number of jobs with seaborn mentioned: {df_visualization[df_visualization.seaborn == 1].shape[0]}')\n",
    "print(F'Number of jobs with dash mentioned: {df_visualization[df_visualization.dash == 1].shape[0]}')\n",
    "print(F'Number of jobs with bokeh mentioned: {df_visualization[df_visualization.bokeh == 1].shape[0]}')\n",
    "print(F'Number of jobs with highcharts mentioned: {df_visualization[df_visualization.highcharts == 1].shape[0]}')\n",
    "print(F'Number of jobs with spotfire mentioned: {df_visualization[df_visualization.spotfire == 1].shape[0]}')\n",
    "print(F'Number of jobs with rshiny mentioned: {df_visualization[df_visualization.rshiny == 1].shape[0]}')\n",
    "print(F'Number of jobs with domo mentioned: {df_visualization[df_visualization.domo == 1].shape[0]}')\n",
    "print(F'Number of jobs with webfocus mentioned: {df_visualization[df_visualization.webfocus == 1].shape[0]}')\n",
    "print(F'Number of jobs with superset mentioned: {df_visualization[df_visualization.superset == 1].shape[0]}')\n",
    "print(F'Number of jobs with google data studio mentioned: {df_visualization[df_visualization.google_data_studio == 1].shape[0]}')\n",
    "print(F'Number of jobs with sisense mentioned: {df_visualization[df_visualization.sisense == 1].shape[0]}')\n",
    "print(F'Number of jobs with chartblocks mentioned: {df_visualization[df_visualization.chartblocks == 1].shape[0]}')\n",
    "print(F'Number of jobs with power bi mentioned: {df_visualization[df_visualization.power_bi == 1].shape[0]}')\n",
    "print(F'Number of jobs with tableau mentioned: {df_visualization[df_visualization.tableau == 1].shape[0]}')\n",
    "print(F'Number of jobs with qlik mentioned: {df_visualization[df_visualization.qlik == 1].shape[0]}')\n",
    "print(F'Number of jobs with google charts mentioned: {df_visualization[df_visualization.google_charts == 1].shape[0]}')\n",
    "print(F'Number of jobs with zoho analytics mentioned: {df_visualization[df_visualization.zoho_analytics == 1].shape[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this code, the df_furher_analysis dataframe is filtered to only include the text_id and job_desc_clean columns, and this new dataframe is saved as df_programming_languages. \n",
    "\n",
    "# A list of programming languages is created, and a function called find_programming_skills is defined. This function takes in a dataframe and one or more skills as parameters. For each skill in the list of skills, the function looks through the job_desc_clean column of the dataframe for that skill, and if it is found, a new column is created in the dataframe with the name of the skill and a value of 1. If the skill is not found, the value in the new column is 0. \n",
    "\n",
    "# The find_programming_skills function is then called on the df_programming_languages dataframe, using the list of programming languages as the skills parameter. \n",
    "\n",
    "# The df_programming_languages dataframe is then filtered again to only include the text_id and columns for each of the programming languages. This new dataframe is then saved as an excel file.\n",
    "\n",
    "\n",
    "df_programming_languages = df_furher_analysis[['text_id','job_desc_clean']].copy()\n",
    "\n",
    "programming_languages = ['python','java', 'javascript', 'sql', 'html','matlab', 'sas', 'spss', 'stata','scala','spark','sparksql','pyspark'] # r is not in the list because of regex issue\n",
    "\n",
    "def find_programming_skills(dataframe, *skills):\n",
    "    for skill in skills:\n",
    "        dataframe[skill] = dataframe['job_desc_clean'].str.contains(f'{skill}', case=False, regex=True).astype(int)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "df_programming_languages = find_programming_skills(df_programming_languages, *programming_languages)\n",
    "\n",
    "df_programming_languages = df_programming_languages[['text_id','python','java', 'javascript', 'sql', 'html','matlab', 'sas', 'spss', 'stata','scala','spark','sparksql','pyspark']].copy()\n",
    "df_programming_languages.head(5)\n",
    "\n",
    "df_programming_languages.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/06_tableau_analysis_programming_languages.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with python mentioned: 1102\n",
      "Number of jobs with java mentioned: 353\n",
      "Number of jobs with javascript mentioned: 92\n",
      "Number of jobs with sql mentioned: 1145\n",
      "Number of jobs with html mentioned: 36\n",
      "Number of jobs with matlab mentioned: 47\n",
      "Number of jobs with sas mentioned: 119\n",
      "Number of jobs with spss mentioned: 27\n",
      "Number of jobs with stata mentioned: 17\n",
      "Number of jobs with scala mentioned: 326\n",
      "Number of jobs with spark mentioned: 298\n",
      "Number of jobs with sparksql mentioned: 0\n",
      "Number of jobs with pyspark mentioned: 24\n"
     ]
    }
   ],
   "source": [
    "print(F'Number of jobs with python mentioned: {df_programming_languages[df_programming_languages.python == 1].shape[0]}')\n",
    "print(F'Number of jobs with java mentioned: {df_programming_languages[df_programming_languages.java == 1].shape[0]}')\n",
    "print(F'Number of jobs with javascript mentioned: {df_programming_languages[df_programming_languages.javascript == 1].shape[0]}')\n",
    "print(F'Number of jobs with sql mentioned: {df_programming_languages[df_programming_languages.sql == 1].shape[0]}')\n",
    "print(F'Number of jobs with html mentioned: {df_programming_languages[df_programming_languages.html == 1].shape[0]}')\n",
    "print(F'Number of jobs with matlab mentioned: {df_programming_languages[df_programming_languages.matlab == 1].shape[0]}')\n",
    "print(F'Number of jobs with sas mentioned: {df_programming_languages[df_programming_languages.sas == 1].shape[0]}')\n",
    "print(F'Number of jobs with spss mentioned: {df_programming_languages[df_programming_languages.spss == 1].shape[0]}')\n",
    "print(F'Number of jobs with stata mentioned: {df_programming_languages[df_programming_languages.stata == 1].shape[0]}')\n",
    "print(F'Number of jobs with scala mentioned: {df_programming_languages[df_programming_languages.scala == 1].shape[0]}')\n",
    "print(F'Number of jobs with spark mentioned: {df_programming_languages[df_programming_languages.spark == 1].shape[0]}')\n",
    "print(F'Number of jobs with sparksql mentioned: {df_programming_languages[df_programming_languages.sparksql == 1].shape[0]}')\n",
    "print(F'Number of jobs with pyspark mentioned: {df_programming_languages[df_programming_languages.pyspark == 1].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code creates a new dataframe, df_platforms, which contains the text_id and job_desc_clean columns from the df_furher_analysis dataframe.\n",
    "\n",
    "# Then, it defines a list of platforms, which are AWS, Azure, Snowflake, and Databricks.\n",
    "\n",
    "# Next, it defines a function, platforms, which takes a dataframe and a list of skills as arguments. This function looks for each of the skills in the job description field of the dataframe, and if it finds a match, it creates a new column in the dataframe with a 1 in the row where the match occurred, and a 0 otherwise. The function also looks for matches for the Google BigQuery platform, and does the same thing.\n",
    "\n",
    "# Finally, the code applies the platforms function to the df_platforms dataframe, using the list of platforms as the list of skills to look for.\n",
    "\n",
    "# The code then creates a new dataframe, df_platforms, which contains the text_id, AWS, Azure, Snowflake, Databricks, and Google columns.\n",
    "\n",
    "# The code then saves the df_platforms dataframe to an Excel file.\n",
    "\n",
    "\n",
    "\n",
    "df_platforms = df_furher_analysis[['text_id','job_desc_clean']].copy()\n",
    "\n",
    "list_of_platforms = ['aws','azure','snowflake','databricks']\n",
    "\n",
    "\n",
    "def platforms(dataframe, *skills):\n",
    "    for skill in skills:\n",
    "        dataframe[skill] = dataframe['job_desc_clean'].str.contains(f'{skill}', case=False, regex=True).astype(int)\n",
    "        dataframe['google'] = dataframe['job_desc_clean'].str.contains('google bigquery|bigquery|google cloud', case=False, regex=True).astype(int)\n",
    "    return dataframe\n",
    "df_platforms = platforms(df_platforms, *list_of_platforms)\n",
    "\n",
    "\n",
    "df_platforms = df_platforms[['text_id','aws','azure','snowflake','databricks','google']].copy()\n",
    "df_platforms.head(5)\n",
    "df_platforms.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/07_tableau_analysis_platforms.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with aws mentioned: 367\n",
      "Number of jobs with azure mentioned: 341\n",
      "Number of jobs with snowflake mentioned: 71\n",
      "Number of jobs with databricks mentioned: 84\n",
      "Number of jobs with google mentioned: 139\n"
     ]
    }
   ],
   "source": [
    "print(F'Number of jobs with aws mentioned: {df_platforms[df_platforms.aws == 1].shape[0]}')\n",
    "print(F'Number of jobs with azure mentioned: {df_platforms[df_platforms.azure == 1].shape[0]}')\n",
    "print(F'Number of jobs with snowflake mentioned: {df_platforms[df_platforms.snowflake == 1].shape[0]}')\n",
    "print(F'Number of jobs with databricks mentioned: {df_platforms[df_platforms.databricks == 1].shape[0]}')\n",
    "print(F'Number of jobs with google mentioned: {df_platforms[df_platforms.google == 1].shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The code creates a new dataframe called df_technologies which contains the columns 'text_id' and 'job_desc_clean' from the df_furher_analysis dataframe.\n",
    "# 2. The code defines a list of technologies.\n",
    "# 3. The code defines a function called find_technologies which takes two arguments, a dataframe and a list of technologies.\n",
    "# 4. The function loops through the list of technologies and for each technology:\n",
    "# 4.1. Creates a new column in the dataframe with the name of the technology.\n",
    "# 4.2. Fills the new column with '1' if the technology is mentioned in the job description and '0' if it is not.\n",
    "# 5. The code applies the function to the df_technologies dataframe using the list of technologies defined in step 2.\n",
    "# 6. The code creates a new dataframe called df_technologies which contains the columns from step 5.\n",
    "# 7. The code exports the df_technologies dataframe to an Excel file.\n",
    "\n",
    "\n",
    "\n",
    "df_technologies = df_furher_analysis[['text_id','job_desc_clean']].copy()\n",
    "\n",
    "technologies = ['bigsql','cassandra','hadoop','hbase','hdfs','hive','hivesql','trifacta',\n",
    "                'kubernetes','mongodb','mysql','nosql','tsql','s3','redshift','posgres',\n",
    "                'teradata','terraform','alteryx','excel','powerapps','powerpoint','knime','talend',\n",
    "                'y42','fivetran','matillion','pentaho','kafka', 'luigi', 'airflow','etl',\n",
    "                'database','dbt','dynamo','firebase','firestore','git','github','gitlab','bigquery']\n",
    "\n",
    "\n",
    "def find_technologies(dataframe, *skills):\n",
    "\n",
    "    for skill in skills:\n",
    "        dataframe[skill] = dataframe['job_desc_clean'].str.contains(f'{skill}', case=False, regex=True).astype(int)\n",
    "        dataframe['aws_glue'] = dataframe['job_desc_clean'].str.contains('aws glue', case=False, regex=True).astype(int)\n",
    "        dataframe['data_vault'] = dataframe['job_desc_clean'].str.contains('data vault', case=False, regex=True).astype(int)\n",
    "        dataframe['docker'] = dataframe['job_desc_clean'].str.contains('docker|dockering', case=False, regex=True).astype(int)\n",
    "        dataframe['data_lake'] = dataframe['job_desc_clean'].str.contains('data lake', case=False, regex=True).astype(int)\n",
    "        dataframe['azure_synapse_analytics'] = dataframe['job_desc_clean'].str.contains('synapse analytics', case=False, regex=True).astype(int)\n",
    "        dataframe['azure_data_factory'] = dataframe['job_desc_clean'].str.contains('data factory', case=False, regex=True).astype(int)\n",
    "        dataframe['microsoft_office'] = dataframe['job_desc_clean'].str.contains('microsoft office', case=False, regex=True).astype(int)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "df_technologies = find_technologies(df_technologies, *technologies)\n",
    "\n",
    "df_technologies = df_technologies[['text_id','bigsql','cassandra','hadoop','hbase','hdfs','hive','hivesql','trifacta','kubernetes',\n",
    "                                    'mongodb','mysql','nosql','tsql','s3','redshift','posgres','teradata','terraform','alteryx','excel','powerapps',\n",
    "                                    'powerpoint','knime','talend','y42','fivetran','matillion','pentaho','kafka', 'luigi', 'airflow','etl','database',\n",
    "                                    'dbt','dynamo','firebase','firestore','git','github','gitlab','aws_glue','data_vault','docker',\n",
    "                                    'azure_synapse_analytics','azure_data_factory','microsoft_office','data_lake','bigquery']].copy()\n",
    "\n",
    "df_technologies.head(5)\n",
    "\n",
    "df_technologies.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/08_tableau_analysis_technologies.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with bigsql mentioned: 0\n",
      "Number of jobs with cassandra mentioned: 14\n",
      "Number of jobs with hadoop mentioned: 134\n",
      "Number of jobs with hbase mentioned: 10\n",
      "Number of jobs with hdfs mentioned: 7\n",
      "Number of jobs with hive mentioned: 40\n",
      "Number of jobs with hivesql mentioned: 0\n",
      "Number of jobs with data lake mentioned: 121\n",
      "Number of jobs with trifacta mentioned: 3\n",
      "Number of jobs with kubernetes mentioned: 103\n",
      "Number of jobs with mongodb mentioned: 39\n",
      "Number of jobs with mysql mentioned: 69\n",
      "Number of jobs with nosql mentioned: 107\n",
      "Number of jobs with tsql mentioned: 4\n",
      "Number of jobs with s3 mentioned: 0\n",
      "Number of jobs with data factory mentioned: 35\n",
      "Number of jobs with redshift mentioned: 55\n",
      "Number of jobs with posgres mentioned: 0\n",
      "Number of jobs with teradata mentioned: 8\n",
      "Number of jobs with terraform mentioned: 60\n",
      "Number of jobs with alteryx mentioned: 28\n",
      "Number of jobs with excel mentioned: 638\n",
      "Number of jobs with powerapps mentioned: 5\n",
      "Number of jobs with microsoft office mentioned: 30\n",
      "Number of jobs with synapse analytics mentioned: 5\n",
      "Number of jobs with powerpoint mentioned: 42\n",
      "Number of jobs with knime mentioned: 35\n",
      "Number of jobs with talend mentioned: 28\n",
      "Number of jobs with y42 mentioned: 0\n",
      "Number of jobs with fivetran mentioned: 3\n",
      "Number of jobs with matillion mentioned: 2\n",
      "Number of jobs with pentaho mentioned: 14\n",
      "Number of jobs with kafka mentioned: 92\n",
      "Number of jobs with luigi mentioned: 5\n",
      "Number of jobs with aws glue mentioned: 13\n",
      "Number of jobs with data vault mentioned: 30\n",
      "Number of jobs with docker mentioned: 139\n",
      "Number of jobs with bigquery mentioned: 89\n"
     ]
    }
   ],
   "source": [
    "print(F'Number of jobs with bigsql mentioned: {df_technologies[df_technologies.bigsql == 1].shape[0]}')\n",
    "print(F'Number of jobs with cassandra mentioned: {df_technologies[df_technologies.cassandra == 1].shape[0]}')\n",
    "print(F'Number of jobs with hadoop mentioned: {df_technologies[df_technologies.hadoop == 1].shape[0]}')\n",
    "print(F'Number of jobs with hbase mentioned: {df_technologies[df_technologies.hbase == 1].shape[0]}')\n",
    "print(F'Number of jobs with hdfs mentioned: {df_technologies[df_technologies.hdfs == 1].shape[0]}')\n",
    "print(F'Number of jobs with hive mentioned: {df_technologies[df_technologies.hive == 1].shape[0]}')\n",
    "print(F'Number of jobs with hivesql mentioned: {df_technologies[df_technologies.hivesql == 1].shape[0]}')\n",
    "print(F'Number of jobs with data lake mentioned: {df_technologies[df_technologies.data_lake == 1].shape[0]}')\n",
    "print(F'Number of jobs with trifacta mentioned: {df_technologies[df_technologies.trifacta == 1].shape[0]}')\n",
    "print(F'Number of jobs with kubernetes mentioned: {df_technologies[df_technologies.kubernetes == 1].shape[0]}')\n",
    "print(F'Number of jobs with mongodb mentioned: {df_technologies[df_technologies.mongodb == 1].shape[0]}')\n",
    "print(F'Number of jobs with mysql mentioned: {df_technologies[df_technologies.mysql == 1].shape[0]}')\n",
    "print(F'Number of jobs with nosql mentioned: {df_technologies[df_technologies.nosql == 1].shape[0]}')\n",
    "print(F'Number of jobs with tsql mentioned: {df_technologies[df_technologies.tsql == 1].shape[0]}')\n",
    "print(F'Number of jobs with s3 mentioned: {df_technologies[df_technologies.s3 == 1].shape[0]}')\n",
    "print(F'Number of jobs with data factory mentioned: {df_technologies[df_technologies.azure_data_factory == 1].shape[0]}')\n",
    "print(F'Number of jobs with redshift mentioned: {df_technologies[df_technologies.redshift == 1].shape[0]}')\n",
    "print(F'Number of jobs with posgres mentioned: {df_technologies[df_technologies.posgres == 1].shape[0]}')\n",
    "print(F'Number of jobs with teradata mentioned: {df_technologies[df_technologies.teradata == 1].shape[0]}')\n",
    "print(F'Number of jobs with terraform mentioned: {df_technologies[df_technologies.terraform == 1].shape[0]}')\n",
    "print(F'Number of jobs with alteryx mentioned: {df_technologies[df_technologies.alteryx == 1].shape[0]}')\n",
    "print(F'Number of jobs with excel mentioned: {df_technologies[df_technologies.excel == 1].shape[0]}')\n",
    "print(F'Number of jobs with powerapps mentioned: {df_technologies[df_technologies.powerapps == 1].shape[0]}')\n",
    "print(F'Number of jobs with microsoft office mentioned: {df_technologies[df_technologies.microsoft_office == 1].shape[0]}')\n",
    "print(F'Number of jobs with synapse analytics mentioned: {df_technologies[df_technologies.azure_synapse_analytics == 1].shape[0]}')\n",
    "print(F'Number of jobs with powerpoint mentioned: {df_technologies[df_technologies.powerpoint == 1].shape[0]}')\n",
    "print(F'Number of jobs with knime mentioned: {df_technologies[df_technologies.knime == 1].shape[0]}')\n",
    "print(F'Number of jobs with talend mentioned: {df_technologies[df_technologies.talend == 1].shape[0]}')\n",
    "print(F'Number of jobs with y42 mentioned: {df_technologies[df_technologies.y42 == 1].shape[0]}')\n",
    "print(F'Number of jobs with fivetran mentioned: {df_technologies[df_technologies.fivetran == 1].shape[0]}')\n",
    "print(F'Number of jobs with matillion mentioned: {df_technologies[df_technologies.matillion == 1].shape[0]}')\n",
    "print(F'Number of jobs with pentaho mentioned: {df_technologies[df_technologies.pentaho == 1].shape[0]}')\n",
    "print(F'Number of jobs with kafka mentioned: {df_technologies[df_technologies.kafka == 1].shape[0]}')\n",
    "print(F'Number of jobs with luigi mentioned: {df_technologies[df_technologies.luigi == 1].shape[0]}')\n",
    "print(F'Number of jobs with aws glue mentioned: {df_technologies[df_technologies.aws_glue == 1].shape[0]}')\n",
    "print(F'Number of jobs with data vault mentioned: {df_technologies[df_technologies.data_vault == 1].shape[0]}')\n",
    "print(F'Number of jobs with docker mentioned: {df_technologies[df_technologies.docker == 1].shape[0]}')\n",
    "print(F'Number of jobs with bigquery mentioned: {df_technologies[df_technologies.bigquery == 1].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) The first line copies the 'text_id' and 'job_desc_clean' columns from the df_furher_analysis dataframe into a new dataframe called df_softskill.\n",
    "\n",
    "# 2) The second line creates a list of soft skills.\n",
    "\n",
    "# 3) The third line defines a function called find_softskill. This function takes two arguments - a dataframe and a list of skills. For each skill in the list, the function adds a new column to the dataframe with the name of the skill. The values in the column are either 1 (indicating that the skill is mentioned in the job description) or 0 (indicating that the skill is not mentioned in the job description).\n",
    "\n",
    "# 4) The fourth line applies the find_softskill function to the df_softskill dataframe, using the list of soft skills created in the second line as the list of skills.\n",
    "\n",
    "# 5) The fifth line keeps only the columns that were created in the fourth line (i.e. the columns containing the soft skills).\n",
    "\n",
    "# 6) The sixth line keeps only the columns that were created in the fourth line (i.e. the columns containing the soft skills) and saves them to a new Excel file.\n",
    "\n",
    "\n",
    "df_softskill = df_furher_analysis[['text_id','job_desc_clean']].copy()\n",
    "\n",
    "list_of_softskills = ['communication', 'verbal', 'written', 'oral','crossfunctional','crossorganizational', 'multifunctional', 'teamwork', 'collaboration','critical thinking','attention to detail','interpersonal']\n",
    "\n",
    "def find_softskill(dataframe, *skills):\n",
    "    for skill in skills:\n",
    "        dataframe[skill] = dataframe['job_desc_clean'].str.contains(f'{skill}', case=False, regex=True).astype(int)\n",
    "    dataframe['presentation_skills'] = dataframe['job_desc_clean'].str.contains('presentation skills', case=False, regex=True).astype(int)\n",
    "    dataframe['critical_thinking'] = dataframe['job_desc_clean'].str.contains('critical thinking', case=False, regex=True).astype(int)\n",
    "    dataframe['problem_solving'] = dataframe['job_desc_clean'].str.contains('problem solving', case=False, regex=True).astype(int)\n",
    "    dataframe['decision_making'] = dataframe['job_desc_clean'].str.contains('decision making', case=False, regex=True).astype(int)\n",
    "    dataframe['attention_to_detail'] = dataframe['job_desc_clean'].str.contains('attention to detail', case=False, regex=True).astype(int)\n",
    "    dataframe['analytical_skills'] = dataframe['job_desc_clean'].str.contains('analytical skills', case=False, regex=True).astype(int)\n",
    "    return dataframe\n",
    "df_softskill = find_softskill(df_softskill, *list_of_softskills)\n",
    "\n",
    "df_softskill = df_softskill[['text_id','communication', 'verbal', 'written', 'oral','crossfunctional','crossorganizational', \n",
    "                            'multifunctional', 'teamwork', 'collaboration','critical thinking','attention to detail','interpersonal',\n",
    "                            'presentation_skills','critical_thinking','problem_solving','decision_making','attention_to_detail','analytical_skills']]\n",
    "\n",
    "\n",
    "df_softskill = df_softskill[['text_id','communication', 'verbal', 'written', 'oral','crossfunctional','crossorganizational','multifunctional', \n",
    "                                'teamwork', 'collaboration','critical thinking','attention to detail','interpersonal','presentation_skills',\n",
    "                                'critical_thinking','problem_solving','decision_making','attention_to_detail','analytical_skills']]\n",
    "\n",
    "df_softskill.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/09_tableau_analysis_softskills.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with communication mentioned: 983\n",
      "Number of jobs with verbal mentioned: 75\n",
      "Number of jobs with written mentioned: 308\n",
      "Number of jobs with oral mentioned: 83\n",
      "Number of jobs with crossfunctional mentioned: 0\n",
      "Number of jobs with crossorganizational mentioned: 0\n",
      "Number of jobs with multifunctional mentioned: 2\n",
      "Number of jobs with teamwork mentioned: 239\n",
      "Number of jobs with collaboration mentioned: 179\n",
      "Number of jobs with critical thinking mentioned: 5\n",
      "Number of jobs with interpersonal mentioned: 35\n",
      "Number of jobs with attention to detail mentioned: 0\n",
      "Number of jobs with analytical skills mentioned: 170\n",
      "Number of jobs with presentation skills mentioned: 69\n",
      "Number of jobs with problem solving mentioned: 139\n",
      "Number of jobs with decision making mentioned: 211\n"
     ]
    }
   ],
   "source": [
    "print(F'Number of jobs with communication mentioned: {df_softskill[df_softskill.communication == 1].shape[0]}')\n",
    "print(F'Number of jobs with verbal mentioned: {df_softskill[df_softskill.verbal == 1].shape[0]}')\n",
    "print(F'Number of jobs with written mentioned: {df_softskill[df_softskill.written == 1].shape[0]}')\n",
    "print(F'Number of jobs with oral mentioned: {df_softskill[df_softskill.oral == 1].shape[0]}')\n",
    "print(F'Number of jobs with crossfunctional mentioned: {df_softskill[df_softskill.crossfunctional == 1].shape[0]}')\n",
    "print(F'Number of jobs with crossorganizational mentioned: {df_softskill[df_softskill.crossorganizational == 1].shape[0]}')\n",
    "print(F'Number of jobs with multifunctional mentioned: {df_softskill[df_softskill.multifunctional == 1].shape[0]}')\n",
    "print(F'Number of jobs with teamwork mentioned: {df_softskill[df_softskill.teamwork == 1].shape[0]}')\n",
    "print(F'Number of jobs with collaboration mentioned: {df_softskill[df_softskill.collaboration == 1].shape[0]}')\n",
    "print(F'Number of jobs with critical thinking mentioned: {df_softskill[df_softskill.critical_thinking == 1].shape[0]}')\n",
    "print(F'Number of jobs with interpersonal mentioned: {df_softskill[df_softskill.interpersonal == 1].shape[0]}')\n",
    "print(F'Number of jobs with attention to detail mentioned: {df_softskill[df_softskill.attention_to_detail == 1].shape[0]}')\n",
    "print(F'Number of jobs with analytical skills mentioned: {df_softskill[df_softskill.analytical_skills == 1].shape[0]}')\n",
    "print(F'Number of jobs with presentation skills mentioned: {df_softskill[df_softskill.presentation_skills == 1].shape[0]}')\n",
    "print(F'Number of jobs with problem solving mentioned: {df_softskill[df_softskill.problem_solving == 1].shape[0]}')\n",
    "print(F'Number of jobs with decision making mentioned: {df_softskill[df_softskill.decision_making == 1].shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code takes a dataframe of job descriptions, creates bigrams for each job description, and then looks for certain bigrams that are related to machine learning skills.\n",
    "#  For each machine learning skill, a new column is created in the dataframe, and the value in that column corresponds to whether or not that skill was found in the job description. Finally, the dataframe is exported to an excel file.\n",
    "\n",
    "\n",
    "df_ml_skills = df_furher_analysis[['text_id','job_desc_clean']].copy()\n",
    "\n",
    "def create_bigrams(dataframe):\n",
    "    dataframe['job_desc_bigrams'] = dataframe['job_desc_clean'].apply(lambda x: list(nltk.bigrams(x.split())))\n",
    "    return dataframe\n",
    "df_ml_skills = create_bigrams(df_ml_skills)\n",
    "\n",
    "ml_skills =  [('machine','learning'), ('predictive', 'modeling'), ('linear', 'regression'), ('logistic', 'regression'), ('k','means'), ('random', 'forest'), ('naive', 'bayes'), ('pca', 'svd'), ('decision', 'tree'), ('ensemble', 'model')]\n",
    "\n",
    "def create_columns_for_ml_skills(dataframe, column_name, list_of_bigrams):\n",
    "    for bigram in list_of_bigrams:\n",
    "        dataframe[bigram] = dataframe[column_name].apply(lambda x: 1 if bigram in x else 0)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "df_ml_skills = create_columns_for_ml_skills(df_ml_skills, 'job_desc_bigrams', ml_skills)\n",
    "\n",
    "\n",
    "def rename_ml_skills_columns(dataframe):\n",
    "\n",
    "    dataframe = dataframe.rename(columns = {dataframe.columns[-1] : 'ensemble_model', dataframe.columns[-2] : 'decision_tree', dataframe.columns[-3] : 'pca_svd', dataframe.columns[-4] : 'naive_bayes', \n",
    "                                                dataframe.columns[-5] : 'random_forest', dataframe.columns[-6] : 'k_means', dataframe.columns[-7] : 'logistic_regression', dataframe.columns[-8] : 'linear_regression', \n",
    "                                                dataframe.columns[-9] : 'predictive_modeling', dataframe.columns[-10] : 'machine_learning'})\n",
    "    return dataframe\n",
    "df_ml_skills = rename_ml_skills_columns(df_ml_skills)\n",
    "\n",
    "\n",
    "df_ml_skills = df_ml_skills[['text_id','ensemble_model', 'decision_tree', 'pca_svd', 'naive_bayes', 'random_forest', 'k_means', 'logistic_regression', \n",
    "                            'linear_regression', 'predictive_modeling', 'machine_learning']]\n",
    "df_ml_skills.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/10_tableau_analysis_ml_skills.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with ensemble model mentioned: 0\n",
      "Number of jobs with decision tree mentioned: 8\n",
      "Number of jobs with pca svd mentioned: 0\n",
      "Number of jobs with naive bayes mentioned: 1\n",
      "Number of jobs with random forest mentioned: 10\n",
      "Number of jobs with k means mentioned: 0\n",
      "Number of jobs with logistic regression mentioned: 4\n",
      "Number of jobs with linear regression mentioned: 1\n",
      "Number of jobs with predictive modeling mentioned: 24\n",
      "Number of jobs with machine learning mentioned: 594\n"
     ]
    }
   ],
   "source": [
    "print(F'Number of jobs with ensemble model mentioned: {df_ml_skills[df_ml_skills.ensemble_model == 1].shape[0]}')\n",
    "print(F'Number of jobs with decision tree mentioned: {df_ml_skills[df_ml_skills.decision_tree == 1].shape[0]}')\n",
    "print(F'Number of jobs with pca svd mentioned: {df_ml_skills[df_ml_skills.pca_svd == 1].shape[0]}')\n",
    "print(F'Number of jobs with naive bayes mentioned: {df_ml_skills[df_ml_skills.naive_bayes == 1].shape[0]}')\n",
    "print(F'Number of jobs with random forest mentioned: {df_ml_skills[df_ml_skills.random_forest == 1].shape[0]}')\n",
    "print(F'Number of jobs with k means mentioned: {df_ml_skills[df_ml_skills.k_means == 1].shape[0]}')\n",
    "print(F'Number of jobs with logistic regression mentioned: {df_ml_skills[df_ml_skills.logistic_regression == 1].shape[0]}')\n",
    "print(F'Number of jobs with linear regression mentioned: {df_ml_skills[df_ml_skills.linear_regression == 1].shape[0]}')\n",
    "print(F'Number of jobs with predictive modeling mentioned: {df_ml_skills[df_ml_skills.predictive_modeling == 1].shape[0]}')\n",
    "print(F'Number of jobs with machine learning mentioned: {df_ml_skills[df_ml_skills.machine_learning == 1].shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This code is creating a dataframe with job descriptions and the corresponding text ID. It then uses the function \"create_bigrams\" to create a column of bigrams for each job description. \n",
    "# The function \"create_columns_for_deep_learning_skills\" then creates a column for each of the deep learning skills listed in \"list_of_deep_learning_skills\" and puts a 1 in the column if the skill is mentioned in the job description, and a 0 if it is not. \n",
    "# The function \"rename_deep_learning_skills_columns\" then renames the columns so that they are more easily interpretable. Finally, the code outputs the dataframe to an Excel file.\n",
    "\n",
    "\n",
    "df_deep_learning_skills = df_furher_analysis[['text_id','job_desc_clean']].copy()\n",
    "\n",
    "def create_bigrams(dataframe):\n",
    "    dataframe['job_desc_bigrams'] = dataframe['job_desc_clean'].apply(lambda x: list(nltk.bigrams(x.split())))\n",
    "    return dataframe\n",
    "deep_learning_skills_df = create_bigrams(df_deep_learning_skills)\n",
    "\n",
    "list_of_deep_learning_skills = [('neural','network'), ('deep', 'learning'), ('object', 'detection'), ('keras', 'tensorflow'), ('convolutional', 'neural')]\n",
    "\n",
    "def create_columns_for_deep_learning_skills(dataframe, column_name, list_of_bigrams):\n",
    "    for bigram in list_of_bigrams:\n",
    "        dataframe[bigram] = dataframe[column_name].apply(lambda x: 1 if bigram in x else 0)\n",
    "    return dataframe\n",
    "deep_learning_skills_df = create_columns_for_deep_learning_skills(deep_learning_skills_df, 'job_desc_bigrams', list_of_deep_learning_skills)\n",
    "\n",
    "def rename_deep_learning_skills_columns(dataframe):\n",
    "    dataframe = dataframe.rename(columns = {dataframe.columns[-1] : 'object_detection', dataframe.columns[-2] : 'convolutional_neural', dataframe.columns[-3] : 'keras_tensorflow', dataframe.columns[-4] : 'neural_network', dataframe.columns[-5] : 'deep_learning'})\n",
    "    return dataframe\n",
    "df_deep_learning_skills = rename_deep_learning_skills_columns(deep_learning_skills_df)\n",
    "\n",
    "\n",
    "df_deep_learning_skills = df_deep_learning_skills[['text_id','object_detection', 'convolutional_neural', 'keras_tensorflow', 'neural_network', 'deep_learning']]\n",
    "\n",
    "df_deep_learning_skills.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/11_tableau_analysis_deep_learning_skills.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with neural network mentioned: 91\n",
      "Number of jobs with deep learning mentioned: 3\n",
      "Number of jobs with object detection mentioned: 0\n",
      "Number of jobs with keras tensorflow mentioned: 0\n",
      "Number of jobs with convolutional neural mentioned: 12\n"
     ]
    }
   ],
   "source": [
    "print(F'Number of jobs with neural network mentioned: {df_deep_learning_skills[df_deep_learning_skills.neural_network == 1].shape[0]}')\n",
    "print(F'Number of jobs with deep learning mentioned: {df_deep_learning_skills[df_deep_learning_skills.deep_learning == 1].shape[0]}')\n",
    "print(F'Number of jobs with object detection mentioned: {df_deep_learning_skills[df_deep_learning_skills.object_detection == 1].shape[0]}')\n",
    "print(F'Number of jobs with keras tensorflow mentioned: {df_deep_learning_skills[df_deep_learning_skills.keras_tensorflow == 1].shape[0]}')\n",
    "print(F'Number of jobs with convolutional neural mentioned: {df_deep_learning_skills[df_deep_learning_skills.convolutional_neural == 1].shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code creates a new dataframe, df_languages_required, that contains the text_id and job_desc_clean columns from the original dataframe, df_furher_analysis.\n",
    "\n",
    "# A list of languages, list_of_language_required, is created.\n",
    "\n",
    "# A function, find_language, is created that takes a dataframe and a list of languages as arguments. The function searches the job_desc_clean column of the dataframe for each language in the list and creates a new column in the dataframe for each language. The function returns the dataframe.\n",
    "\n",
    "# The function is called on the df_languages_required dataframe using the list of languages as arguments. This creates new columns in the df_languages_required dataframe for each language in the list.\n",
    "\n",
    "# The df_languages_required dataframe is filtered to only contain the text_id and language columns.\n",
    "\n",
    "\n",
    "df_languages_required = df_furher_analysis[['text_id','job_desc_clean']].copy()\n",
    "\n",
    "list_of_language_required = ['english', 'french', 'spanish', 'german', 'italian', 'portuguese', 'russian', 'chinese', 'japanese', 'ukrainian', 'arabic', 'hebrew']\n",
    "\n",
    "def find_language(dataframe, *languages):\n",
    "    for language in languages:\n",
    "        dataframe[language] = dataframe['job_desc_clean'].str.contains(f'{language}', case=False, regex=True).astype(int)\n",
    "    return dataframe\n",
    "df_languages_required = find_language(df_languages_required, *list_of_language_required)\n",
    "\n",
    "\n",
    "df_languages_required = df_languages_required[['text_id','english', 'french', 'spanish', 'german', 'italian', 'portuguese', 'russian', 'chinese', 'japanese', 'ukrainian', 'arabic', 'hebrew']]\n",
    "\n",
    "df_languages_required.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/12_tableau_analysis_languages_required.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with english mentioned: 1329\n",
      "Number of jobs with french mentioned: 19\n",
      "Number of jobs with spanish mentioned: 5\n",
      "Number of jobs with german mentioned: 1359\n",
      "Number of jobs with italian mentioned: 2\n",
      "Number of jobs with portuguese mentioned: 0\n",
      "Number of jobs with russian mentioned: 2\n",
      "Number of jobs with chinese mentioned: 1\n",
      "Number of jobs with japanese mentioned: 2\n",
      "Number of jobs with ukrainian mentioned: 1\n",
      "Number of jobs with arabic mentioned: 0\n",
      "Number of jobs with hebrew mentioned: 0\n"
     ]
    }
   ],
   "source": [
    "print(F'Number of jobs with english mentioned: {df_languages_required[df_languages_required.english == 1].shape[0]}')\n",
    "print(F'Number of jobs with french mentioned: {df_languages_required[df_languages_required.french == 1].shape[0]}')\n",
    "print(F'Number of jobs with spanish mentioned: {df_languages_required[df_languages_required.spanish == 1].shape[0]}')\n",
    "print(F'Number of jobs with german mentioned: {df_languages_required[df_languages_required.german == 1].shape[0]}')\n",
    "print(F'Number of jobs with italian mentioned: {df_languages_required[df_languages_required.italian == 1].shape[0]}')\n",
    "print(F'Number of jobs with portuguese mentioned: {df_languages_required[df_languages_required.portuguese == 1].shape[0]}')\n",
    "print(F'Number of jobs with russian mentioned: {df_languages_required[df_languages_required.russian == 1].shape[0]}')\n",
    "print(F'Number of jobs with chinese mentioned: {df_languages_required[df_languages_required.chinese == 1].shape[0]}')\n",
    "print(F'Number of jobs with japanese mentioned: {df_languages_required[df_languages_required.japanese == 1].shape[0]}')\n",
    "print(F'Number of jobs with ukrainian mentioned: {df_languages_required[df_languages_required.ukrainian == 1].shape[0]}')\n",
    "print(F'Number of jobs with arabic mentioned: {df_languages_required[df_languages_required.arabic == 1].shape[0]}')\n",
    "print(F'Number of jobs with hebrew mentioned: {df_languages_required[df_languages_required.hebrew == 1].shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is creating a new dataframe that only contains the \"text_id\" and \"job_desc_clean\" columns from the \"df_furher_analysis\" dataframe. \n",
    "# This new dataframe is called \"df_projectsmanagement_skills_and_methodologies\".\n",
    "\n",
    "# There is also a list called \"list_of_projectmanagement_skills_and_methodologies\" which contains a list of project management skills and methodologies. \n",
    "\n",
    "# There is a function called \"find_projectmanagement_skills_and_methodologies\" which takes in a dataframe and a list of project management skills and methodologies. \n",
    "# This function looks through the \"job_desc_clean\" column in the dataframe and looks for each of the project management skills and methodologies in the list. \n",
    "# If it finds a match, it will create a new column in the dataframe with the name of the skill or methodology and put a \"1\" in the cells of that column for each row where there was a match.\n",
    "# If it doesn't find a match, it will create a new column in the dataframe with the name of the skill or methodology and put a \"0\" in the cells of that column for each row where there wasn't a match.\n",
    "\n",
    "# The function also looks for other project management skills and methodologies that weren't in the list (team management, organization management, project planning, time management, project scheduling, and project budgeting)\n",
    "# and does the same thing. \n",
    "\n",
    "# After the function is done running, it returns the dataframe. \n",
    "\n",
    "# The code then takes the dataframe that was returned from the function and puts it into the \"df_projectsmanagement_skills_and_methodologies\" dataframe. \n",
    "# It also only keeps the columns that we care about and gets rid of the rest. \n",
    "\n",
    "# Finally, the code exports the dataframe to an Excel file.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_projectsmanagement_skills_and_methodologies= df_furher_analysis[['text_id','job_desc_clean']].copy()\n",
    "\n",
    "\n",
    "list_of_projectmanagement_skills_and_methodologies = ['negotiation','leadership','waterfall','agile', 'scrum','lean','adaptability','patience']\n",
    "\n",
    "def find_projectmanagement_skills_and_methodologies(dataframe, *list_of_projectmanagement_skills_and_methodologies):\n",
    "    for skill in list_of_projectmanagement_skills_and_methodologies:\n",
    "        dataframe[skill] = dataframe['job_desc_clean'].str.contains(f'{skill}', case=False, regex=True).astype(int)\n",
    "\n",
    "    dataframe['team_management'] = dataframe['job_desc_clean'].str.contains('team_management', case=False, regex=True).astype(int)\n",
    "    dataframe['organization_management'] = dataframe['job_desc_clean'].str.contains('organization management', case=False, regex=True).astype(int)\n",
    "    dataframe['project_planning'] = dataframe['job_desc_clean'].str.contains('project planning', case=False, regex=True).astype(int)\n",
    "    dataframe['time_management'] = dataframe['job_desc_clean'].str.contains('time management', case=False, regex=True).astype(int)\n",
    "    dataframe['project_scheduling'] = dataframe['job_desc_clean'].str.contains('project scheduling', case=False, regex=True).astype(int)\n",
    "    dataframe['project_budgeting'] = dataframe['job_desc_clean'].str.contains('project budgeting', case=False, regex=True).astype(int)\n",
    "    dataframe['prince2'] = dataframe['job_desc_clean'].str.contains('prince', case=False, regex=True).astype(int)\n",
    "    return dataframe\n",
    "\n",
    "df_projectsmanagement_skills_and_methodologies = find_projectmanagement_skills_and_methodologies(df_projectsmanagement_skills_and_methodologies, *list_of_projectmanagement_skills_and_methodologies)\n",
    "df_projectsmanagement_skills_and_methodologies\n",
    "\n",
    "df_projectsmanagement_skills_and_methodologies = df_projectsmanagement_skills_and_methodologies[['text_id','negotiation', 'leadership', 'waterfall', 'lean','agile', 'scrum', 'prince2', \n",
    "                                                'adaptability', 'patience', 'team_management', 'organization_management', 'project_planning', 'time_management', \n",
    "                                                'project_scheduling', 'project_budgeting']]\n",
    "\n",
    "\n",
    "df_projectsmanagement_skills_and_methodologies.to_excel('Master/04_Analysis/04_01_custom_analysis/04_01_02_tableau_data/13_tableau_analysis_project_management_skills_and_methodologies.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with negotiation mentioned: 41\n",
      "Number of jobs with leadership mentioned: 127\n",
      "Number of jobs with waterfall mentioned: 11\n",
      "Number of jobs with agile mentioned: 694\n",
      "Number of jobs with scrum mentioned: 117\n",
      "Number of jobs with lean mentioned: 148\n",
      "Number of jobs with prince2 mentioned: 6\n",
      "Number of jobs with adaptability mentioned: 3\n",
      "Number of jobs with patience mentioned: 1\n",
      "Number of jobs with time_management mentioned: 17\n",
      "Number of jobs with organization_management mentioned: 1\n",
      "Number of jobs with project_planning mentioned: 12\n",
      "Number of jobs with project_scheduling mentioned: 0\n",
      "Number of jobs with project_budgeting mentioned: 0\n"
     ]
    }
   ],
   "source": [
    "print(F'Number of jobs with negotiation mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.negotiation == 1].shape[0]}')\n",
    "print(F'Number of jobs with leadership mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.leadership == 1].shape[0]}')\n",
    "print(F'Number of jobs with waterfall mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.waterfall == 1].shape[0]}')\n",
    "print(F'Number of jobs with agile mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.agile == 1].shape[0]}')\n",
    "print(F'Number of jobs with scrum mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.scrum == 1].shape[0]}')\n",
    "print(F'Number of jobs with lean mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.lean == 1].shape[0]}')\n",
    "print(F'Number of jobs with prince2 mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.prince2 == 1].shape[0]}')\n",
    "print(F'Number of jobs with adaptability mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.adaptability == 1].shape[0]}')\n",
    "print(F'Number of jobs with patience mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.patience == 1].shape[0]}')\n",
    "print(F'Number of jobs with time_management mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.time_management == 1].shape[0]}')\n",
    "print(F'Number of jobs with organization_management mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.organization_management == 1].shape[0]}')\n",
    "print(F'Number of jobs with project_planning mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.project_planning == 1].shape[0]}')\n",
    "print(F'Number of jobs with project_scheduling mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.project_scheduling == 1].shape[0]}')\n",
    "print(F'Number of jobs with project_budgeting mentioned: {df_projectsmanagement_skills_and_methodologies[df_projectsmanagement_skills_and_methodologies.project_budgeting == 1].shape[0]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
